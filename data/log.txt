2024-12-11 14:45:32
dev_data/collectors/collectors.py: {
    "dev_data/collectors/collectors.py": [
        {
            "class_name": "DataCollectorBase",
            "bases": [
                "IterableDataset"
            ],
            "docstring": "Base class for data collectors.",
            "description": "",
            "overview": "",
            "functions": [
                {
                    "function_name": "update_policy_weights_",
                    "args": [
                        {
                            "arg_name": "policy_weights",
                            "return_type": "Optional[TensorDictBase]",
                            "default_value": "None",
                            "description": ""
                        }
                    ],
                    "signature": "update_policy_weights_(self, policy_weights: Optional[TensorDictBase]=None) -> None",
                    "function_code": "def update_policy_weights_(self, policy_weights: Optional[TensorDictBase]=None) -> None:\n    \"\"\"Updates the policy weights if the policy of the data collector and the trained policy live on different devices.\n\n        Args:\n            policy_weights (TensorDictBase, optional): if provided, a TensorDict containing\n                the weights of the policy to be used for the udpdate.\n\n        \"\"\"\n    if policy_weights is not None:\n        self.policy_weights.data.update_(policy_weights)\n    elif self.get_weights_fn is not None:\n        self.policy_weights.data.update_(self.get_weights_fn())",
                    "docstring": "Updates the policy weights if the policy of the data collector and the trained policy live on different devices.\n\nArgs:\n    policy_weights (TensorDictBase, optional): if provided, a TensorDict containing\n        the weights of the policy to be used for the udpdate.",
                    "description": ""
                },
                {
                    "function_name": "next",
                    "args": [],
                    "signature": "next(self)",
                    "function_code": "def next(self):\n    try:\n        if self._iterator is None:\n            self._iterator = iter(self)\n        out = next(self._iterator)\n        out.clear_device_()\n        return out\n    except StopIteration:\n        return None",
                    "docstring": "",
                    "description": ""
                },
                {
                    "function_name": "shutdown",
                    "args": [],
                    "signature": "shutdown(self)",
                    "function_code": "@abc.abstractmethod\ndef shutdown(self):\n    raise NotImplementedError",
                    "docstring": "",
                    "description": ""
                },
                {
                    "function_name": "iterator",
                    "args": [],
                    "signature": "iterator(self) -> Iterator[TensorDictBase]",
                    "function_code": "@abc.abstractmethod\ndef iterator(self) -> Iterator[TensorDictBase]:\n    raise NotImplementedError",
                    "docstring": "",
                    "description": ""
                },
                {
                    "function_name": "set_seed",
                    "args": [
                        {
                            "arg_name": "seed",
                            "return_type": "int",
                            "default_value": "",
                            "description": ""
                        },
                        {
                            "arg_name": "static_seed",
                            "return_type": "bool",
                            "default_value": "False",
                            "description": ""
                        }
                    ],
                    "signature": "set_seed(self, seed: int, static_seed: bool=False) -> int",
                    "function_code": "@abc.abstractmethod\ndef set_seed(self, seed: int, static_seed: bool=False) -> int:\n    raise NotImplementedError",
                    "docstring": "",
                    "description": ""
                },
                {
                    "function_name": "state_dict",
                    "args": [],
                    "signature": "state_dict(self) -> OrderedDict",
                    "function_code": "@abc.abstractmethod\ndef state_dict(self) -> OrderedDict:\n    raise NotImplementedError",
                    "docstring": "",
                    "description": ""
                },
                {
                    "function_name": "load_state_dict",
                    "args": [
                        {
                            "arg_name": "state_dict",
                            "return_type": "OrderedDict",
                            "default_value": "",
                            "description": ""
                        }
                    ],
                    "signature": "load_state_dict(self, state_dict: OrderedDict) -> None",
                    "function_code": "@abc.abstractmethod\ndef load_state_dict(self, state_dict: OrderedDict) -> None:\n    raise NotImplementedError",
                    "docstring": "",
                    "description": ""
                }
            ]
        }
    ]
}
2024-12-11 14:46:55
dev_data/collectors/utils.py: {
    "dev_data/collectors/utils.py": [
        {
            "function_name": "split_trajectories",
            "args": [
                {
                    "arg_name": "rollout_tensordict",
                    "return_type": "TensorDictBase",
                    "default_value": "",
                    "description": ""
                },
                {
                    "arg_name": "prefix",
                    "return_type": "",
                    "default_value": "None",
                    "description": ""
                },
                {
                    "arg_name": "trajectory_key",
                    "return_type": "NestedKey | None",
                    "default_value": "None",
                    "description": ""
                },
                {
                    "arg_name": "done_key",
                    "return_type": "NestedKey | None",
                    "default_value": "None",
                    "description": ""
                },
                {
                    "arg_name": "as_nested",
                    "return_type": "bool",
                    "default_value": "False",
                    "description": ""
                }
            ],
            "signature": "split_trajectories(rollout_tensordict: TensorDictBase, *, prefix=None, trajectory_key: NestedKey | None=None, done_key: NestedKey | None=None, as_nested: bool=False) -> TensorDictBase",
            "function_code": "@set_lazy_legacy(False)\ndef split_trajectories(rollout_tensordict: TensorDictBase, *, prefix=None, trajectory_key: NestedKey | None=None, done_key: NestedKey | None=None, as_nested: bool=False) -> TensorDictBase:\n    \"\"\"A util function for trajectory separation.\n\n    Takes a tensordict with a key traj_ids that indicates the id of each trajectory.\n\n    From there, builds a B x T x ... zero-padded tensordict with B batches on max duration T\n\n    Args:\n        rollout_tensordict (TensorDictBase): a rollout with adjacent trajectories\n            along the last dimension.\n\n    Keyword Args:\n        prefix (NestedKey, optional): the prefix used to read and write meta-data,\n            such as ``\"traj_ids\"`` (the optional integer id of each trajectory)\n            and the ``\"mask\"`` entry indicating which data are valid and which\n            aren't. Defaults to ``\"collector\"`` if the input has a ``\"collector\"``\n            entry, ``()`` (no prefix) otherwise.\n            ``prefix`` is kept as a legacy feature and will be deprecated eventually.\n            Prefer ``trajectory_key`` or ``done_key`` whenever possible.\n        trajectory_key (NestedKey, optional): the key pointing to the trajectory\n            ids. Supersedes ``done_key`` and ``prefix``. If not provided, defaults\n            to ``(prefix, \"traj_ids\")``.\n        done_key (NestedKey, optional): the key pointing to the ``\"done\"\"`` signal,\n            if the trajectory could not be directly recovered. Defaults to ``\"done\"``.\n        as_nested (bool or torch.layout, optional): whether to return the results as nested\n            tensors. Defaults to ``False``. If a ``torch.layout`` is provided, it will be used\n            to construct the nested tensor, otherwise the default layout will be used.\n\n            .. note:: Using ``split_trajectories(tensordict, as_nested=True).to_padded_tensor(mask=mask_key)``\n                should result in the exact same result as ``as_nested=False``. Since this is an experimental\n                feature and relies on nested_tensors, which API may change in the future, we made this\n                an optional feature. The runtime should be faster with ``as_nested=True``.\n\n            .. note:: Providing a layout lets the user control whether the nested tensor is to be used\n                with ``torch.strided`` or ``torch.jagged`` layout. While the former has slightly more\n                capabilities at the time of writing, the second will be the main focus of the PyTorch team\n                in the future due to its better compatibility with :func:`~torch.compile`.\n\n    Returns:\n        A new tensordict with a leading dimension corresponding to the trajectory.\n        A ``\"mask\"`` boolean entry sharing the ``trajectory_key`` prefix\n        and the tensordict shape is also added. It indicated the valid elements of the tensordict,\n        as well as a ``\"traj_ids\"`` entry if ``trajectory_key`` could not be found.\n\n    Examples:\n        >>> from tensordict import TensorDict\n        >>> import torch\n        >>> from torchrl.collectors.utils import split_trajectories\n        >>> obs = torch.cat([torch.arange(10), torch.arange(5)])\n        >>> obs_ = torch.cat([torch.arange(1, 11), torch.arange(1, 6)])\n        >>> done = torch.zeros(15, dtype=torch.bool)\n        >>> done[9] = True\n        >>> trajectory_id = torch.cat([torch.zeros(10, dtype=torch.int32),\n        ...     torch.ones(5, dtype=torch.int32)])\n        >>> data = TensorDict({\"obs\": obs, (\"next\", \"obs\"): obs_, (\"next\", \"done\"): done, \"trajectory\": trajectory_id}, batch_size=[15])\n        >>> data_split = split_trajectories(data, done_key=\"done\")\n        >>> print(data_split)\n        TensorDict(\n            fields={\n                mask: Tensor(shape=torch.Size([2, 10]), device=cpu, dtype=torch.bool, is_shared=False),\n                next: TensorDict(\n                    fields={\n                        done: Tensor(shape=torch.Size([2, 10]), device=cpu, dtype=torch.bool, is_shared=False),\n                        obs: Tensor(shape=torch.Size([2, 10]), device=cpu, dtype=torch.int64, is_shared=False)},\n                    batch_size=torch.Size([2, 10]),\n                    device=None,\n                    is_shared=False),\n                obs: Tensor(shape=torch.Size([2, 10]), device=cpu, dtype=torch.int64, is_shared=False),\n                traj_ids: Tensor(shape=torch.Size([2, 10]), device=cpu, dtype=torch.int64, is_shared=False),\n                trajectory: Tensor(shape=torch.Size([2, 10]), device=cpu, dtype=torch.int32, is_shared=False)},\n            batch_size=torch.Size([2, 10]),\n            device=None,\n            is_shared=False)\n        >>> # check that split_trajectories got the trajectories right with the done signal\n        >>> assert (data_split[\"traj_ids\"] == data_split[\"trajectory\"]).all()\n        >>> print(data_split[\"mask\"])\n        tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n                [ True,  True,  True,  True,  True, False, False, False, False, False]])\n        >>> data_split = split_trajectories(data, trajectory_key=\"trajectory\")\n        >>> print(data_split)\n        TensorDict(\n            fields={\n                mask: Tensor(shape=torch.Size([2, 10]), device=cpu, dtype=torch.bool, is_shared=False),\n                next: TensorDict(\n                    fields={\n                        done: Tensor(shape=torch.Size([2, 10]), device=cpu, dtype=torch.bool, is_shared=False),\n                        obs: Tensor(shape=torch.Size([2, 10]), device=cpu, dtype=torch.int64, is_shared=False)},\n                    batch_size=torch.Size([2, 10]),\n                    device=None,\n                    is_shared=False),\n                obs: Tensor(shape=torch.Size([2, 10]), device=cpu, dtype=torch.int64, is_shared=False),\n                trajectory: Tensor(shape=torch.Size([2, 10]), device=cpu, dtype=torch.int32, is_shared=False)},\n            batch_size=torch.Size([2, 10]),\n            device=None,\n            is_shared=False)\n\n    \"\"\"\n    mask_key = None\n    if trajectory_key is not None:\n        from torchrl.envs.utils import _replace_last\n        traj_ids_key = trajectory_key\n        mask_key = _replace_last(trajectory_key, 'mask')\n    else:\n        if prefix is None and 'collector' in rollout_tensordict.keys():\n            prefix = 'collector'\n        if prefix is None:\n            traj_ids_key = 'traj_ids'\n            mask_key = 'mask'\n        else:\n            traj_ids_key = (prefix, 'traj_ids')\n            mask_key = (prefix, 'mask')\n    rollout_tensordict = rollout_tensordict.copy()\n    traj_ids = rollout_tensordict.get(traj_ids_key, None)\n    if traj_ids is None:\n        if done_key is None:\n            done_key = 'done'\n        done_key = ('next', done_key)\n        done = rollout_tensordict.get(done_key)\n        idx = (slice(None),) * (rollout_tensordict.ndim - 1) + (slice(None, -1),)\n        done_sel = done[idx]\n        pads = [1, 0]\n        pads = [0, 0] * (done.ndim - rollout_tensordict.ndim) + pads\n        done_sel = torch.nn.functional.pad(done_sel, pads)\n        if done_sel.shape != done.shape:\n            raise RuntimeError(f'done and done_sel have different shape {done.shape} - {done_sel.shape} ')\n        traj_ids = done_sel.cumsum(rollout_tensordict.ndim - 1)\n        traj_ids = traj_ids.squeeze(-1)\n        if rollout_tensordict.ndim > 1:\n            for i in range(1, rollout_tensordict.shape[0]):\n                traj_ids[i] += traj_ids[i - 1].max() + 1\n        rollout_tensordict.set(traj_ids_key, traj_ids)\n    splits = traj_ids.reshape(-1)\n    splits = [(splits == i).sum().item() for i in splits.unique_consecutive()]\n    if len(set(splits)) == 1 and splits[0] == traj_ids.shape[-1]:\n        rollout_tensordict.set(mask_key, torch.ones(rollout_tensordict.shape, device=rollout_tensordict.device, dtype=torch.bool))\n        if rollout_tensordict.ndimension() == 1:\n            rollout_tensordict = rollout_tensordict.unsqueeze(0)\n        return rollout_tensordict\n    out_splits = rollout_tensordict.reshape(-1)\n    if as_nested:\n        if hasattr(torch, '_nested_compute_contiguous_strides_offsets'):\n\n            def nest(x, splits=splits):\n                shape = torch.tensor([[int(split), *x.shape[1:]] for split in splits])\n                return torch._nested_view_from_buffer(x.reshape(-1), shape, *torch._nested_compute_contiguous_strides_offsets(shape))\n            return out_splits._fast_apply(nest, batch_size=[len(splits), -1])\n        else:\n            out_splits = out_splits.split(splits, 0)\n            layout = as_nested if as_nested is not bool else None\n            if torch.__version__ < '2.4':\n                if layout not in (True,):\n                    raise RuntimeError(f'layout={layout} is only available for torch>=v2.4')\n\n                def nest(*x):\n                    return torch.nested.nested_tensor(list(x))\n            else:\n\n                def nest(*x):\n                    return torch.nested.nested_tensor(list(x), layout=layout)\n            return out_splits[0]._fast_apply(nest, *out_splits[1:], batch_size=[len(out_splits), *out_splits[0].batch_size[:-1], -1])\n    out_splits = out_splits.split(splits, 0)\n    for out_split in out_splits:\n        out_split.set(mask_key, torch.ones(out_split.shape, dtype=torch.bool, device=out_split.device))\n    if len(out_splits) > 1:\n        MAX = max(*[out_split.shape[0] for out_split in out_splits])\n    else:\n        MAX = out_splits[0].shape[0]\n    td = torch.stack([pad(out_split, [0, MAX - out_split.shape[0]]) for out_split in out_splits], 0)\n    return td",
            "docstring": "A util function for trajectory separation.\n\nTakes a tensordict with a key traj_ids that indicates the id of each trajectory.\n\nFrom there, builds a B x T x ... zero-padded tensordict with B batches on max duration T\n\nArgs:\n    rollout_tensordict (TensorDictBase): a rollout with adjacent trajectories\n        along the last dimension.\n\nKeyword Args:\n    prefix (NestedKey, optional): the prefix used to read and write meta-data,\n        such as ``\"traj_ids\"`` (the optional integer id of each trajectory)\n        and the ``\"mask\"`` entry indicating which data are valid and which\n        aren't. Defaults to ``\"collector\"`` if the input has a ``\"collector\"``\n        entry, ``()`` (no prefix) otherwise.\n        ``prefix`` is kept as a legacy feature and will be deprecated eventually.\n        Prefer ``trajectory_key`` or ``done_key`` whenever possible.\n    trajectory_key (NestedKey, optional): the key pointing to the trajectory\n        ids. Supersedes ``done_key`` and ``prefix``. If not provided, defaults\n        to ``(prefix, \"traj_ids\")``.\n    done_key (NestedKey, optional): the key pointing to the ``\"done\"\"`` signal,\n        if the trajectory could not be directly recovered. Defaults to ``\"done\"``.\n    as_nested (bool or torch.layout, optional): whether to return the results as nested\n        tensors. Defaults to ``False``. If a ``torch.layout`` is provided, it will be used\n        to construct the nested tensor, otherwise the default layout will be used.\n\n        .. note:: Using ``split_trajectories(tensordict, as_nested=True).to_padded_tensor(mask=mask_key)``\n            should result in the exact same result as ``as_nested=False``. Since this is an experimental\n            feature and relies on nested_tensors, which API may change in the future, we made this\n            an optional feature. The runtime should be faster with ``as_nested=True``.\n\n        .. note:: Providing a layout lets the user control whether the nested tensor is to be used\n            with ``torch.strided`` or ``torch.jagged`` layout. While the former has slightly more\n            capabilities at the time of writing, the second will be the main focus of the PyTorch team\n            in the future due to its better compatibility with :func:`~torch.compile`.\n\nReturns:\n    A new tensordict with a leading dimension corresponding to the trajectory.\n    A ``\"mask\"`` boolean entry sharing the ``trajectory_key`` prefix\n    and the tensordict shape is also added. It indicated the valid elements of the tensordict,\n    as well as a ``\"traj_ids\"`` entry if ``trajectory_key`` could not be found.\n\nExamples:\n    >>> from tensordict import TensorDict\n    >>> import torch\n    >>> from torchrl.collectors.utils import split_trajectories\n    >>> obs = torch.cat([torch.arange(10), torch.arange(5)])\n    >>> obs_ = torch.cat([torch.arange(1, 11), torch.arange(1, 6)])\n    >>> done = torch.zeros(15, dtype=torch.bool)\n    >>> done[9] = True\n    >>> trajectory_id = torch.cat([torch.zeros(10, dtype=torch.int32),\n    ...     torch.ones(5, dtype=torch.int32)])\n    >>> data = TensorDict({\"obs\": obs, (\"next\", \"obs\"): obs_, (\"next\", \"done\"): done, \"trajectory\": trajectory_id}, batch_size=[15])\n    >>> data_split = split_trajectories(data, done_key=\"done\")\n    >>> print(data_split)\n    TensorDict(\n        fields={\n            mask: Tensor(shape=torch.Size([2, 10]), device=cpu, dtype=torch.bool, is_shared=False),\n            next: TensorDict(\n                fields={\n                    done: Tensor(shape=torch.Size([2, 10]), device=cpu, dtype=torch.bool, is_shared=False),\n                    obs: Tensor(shape=torch.Size([2, 10]), device=cpu, dtype=torch.int64, is_shared=False)},\n                batch_size=torch.Size([2, 10]),\n                device=None,\n                is_shared=False),\n            obs: Tensor(shape=torch.Size([2, 10]), device=cpu, dtype=torch.int64, is_shared=False),\n            traj_ids: Tensor(shape=torch.Size([2, 10]), device=cpu, dtype=torch.int64, is_shared=False),\n            trajectory: Tensor(shape=torch.Size([2, 10]), device=cpu, dtype=torch.int32, is_shared=False)},\n        batch_size=torch.Size([2, 10]),\n        device=None,\n        is_shared=False)\n    >>> # check that split_trajectories got the trajectories right with the done signal\n    >>> assert (data_split[\"traj_ids\"] == data_split[\"trajectory\"]).all()\n    >>> print(data_split[\"mask\"])\n    tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n            [ True,  True,  True,  True,  True, False, False, False, False, False]])\n    >>> data_split = split_trajectories(data, trajectory_key=\"trajectory\")\n    >>> print(data_split)\n    TensorDict(\n        fields={\n            mask: Tensor(shape=torch.Size([2, 10]), device=cpu, dtype=torch.bool, is_shared=False),\n            next: TensorDict(\n                fields={\n                    done: Tensor(shape=torch.Size([2, 10]), device=cpu, dtype=torch.bool, is_shared=False),\n                    obs: Tensor(shape=torch.Size([2, 10]), device=cpu, dtype=torch.int64, is_shared=False)},\n                batch_size=torch.Size([2, 10]),\n                device=None,\n                is_shared=False),\n            obs: Tensor(shape=torch.Size([2, 10]), device=cpu, dtype=torch.int64, is_shared=False),\n            trajectory: Tensor(shape=torch.Size([2, 10]), device=cpu, dtype=torch.int32, is_shared=False)},\n        batch_size=torch.Size([2, 10]),\n        device=None,\n        is_shared=False)",
            "description": ""
        }
    ]
}
2024-12-11 14:46:57
dev_data/collectors/distributed/utils.py: {
    "dev_data/collectors/distributed/utils.py": [
        {
            "class_name": "submitit_delayed_launcher",
            "bases": [],
            "docstring": "Delayed launcher for submitit.\n\nIn some cases, launched jobs cannot spawn other jobs on their own and this\ncan only be done at the jump-host level.\n\nIn these cases, the :func:`submitit_delayed_launcher` can be used to\npre-launch collector nodes that will wait for the main worker to provide\nthe launching instruction.\n\nArgs:\n    num_jobs (int): the number of collection jobs to be launched.\n    framework (str, optional): the framework to use. Can be either ``\"distributed\"``\n        or ``\"rpc\"``. ``\"distributed\"`` requires a :class:`~.DistributedDataCollector`\n        collector whereas ``\"rpc\"`` requires a :class:`RPCDataCollector`.\n        Defaults to ``\"distributed\"``.\n    backend (str, optional): torch.distributed backend in case ``framework``\n        points to ``\"distributed\"``. This value must match the one passed to\n        the collector, otherwise main and satellite nodes will fail to\n        reach the rendezvous and hang forever (ie no exception will be raised!)\n        Defaults to ``'gloo'``.\n    tcpport (int or str, optional): the TCP port to use.\n        Defaults to :obj:`torchrl.collectors.distributed.default_configs.TCP_PORT`\n    submitit_main_conf (dict, optional): the main node configuration to be passed to submitit.\n        Defaults to :obj:`torchrl.collectors.distributed.default_configs.DEFAULT_SLURM_CONF_MAIN`\n    submitit_collection_conf (dict, optional): the configuration to be passed to submitit.\n        Defaults to :obj:`torchrl.collectors.distributed.default_configs.DEFAULT_SLURM_CONF`\n\nExamples:\n    >>> num_jobs=2\n    >>> @submitit_delayed_launcher(num_jobs=num_jobs)\n    ... def main():\n    ...     from torchrl.envs.utils import RandomPolicy\n            from torchrl.envs.libs.gym import GymEnv\n    ...     from torchrl.data import BoundedContinuous\n    ...     collector = DistributedDataCollector(\n    ...         [EnvCreator(lambda: GymEnv(\"Pendulum-v1\"))] * num_jobs,\n    ...         policy=RandomPolicy(BoundedContinuous(-1, 1, shape=(1,))),\n    ...         launcher=\"submitit_delayed\",\n    ...     )\n    ...     for data in collector:\n    ...         print(data)\n    ...\n    >>> if __name__ == \"__main__\":\n    ...     main()\n    ...",
            "description": "",
            "overview": "",
            "functions": [
                {
                    "function_name": "__init__",
                    "args": [
                        {
                            "arg_name": "num_jobs",
                            "return_type": "",
                            "default_value": "",
                            "description": ""
                        },
                        {
                            "arg_name": "framework",
                            "return_type": "",
                            "default_value": "'distributed'",
                            "description": ""
                        },
                        {
                            "arg_name": "backend",
                            "return_type": "",
                            "default_value": "'gloo'",
                            "description": ""
                        },
                        {
                            "arg_name": "tcpport",
                            "return_type": "",
                            "default_value": "TCP_PORT",
                            "description": ""
                        },
                        {
                            "arg_name": "submitit_main_conf",
                            "return_type": "dict",
                            "default_value": "DEFAULT_SLURM_CONF_MAIN",
                            "description": ""
                        },
                        {
                            "arg_name": "submitit_collection_conf",
                            "return_type": "dict",
                            "default_value": "DEFAULT_SLURM_CONF",
                            "description": ""
                        }
                    ],
                    "signature": "__init__(self, num_jobs, framework='distributed', backend='gloo', tcpport=TCP_PORT, submitit_main_conf: dict=DEFAULT_SLURM_CONF_MAIN, submitit_collection_conf: dict=DEFAULT_SLURM_CONF)",
                    "function_code": "def __init__(self, num_jobs, framework='distributed', backend='gloo', tcpport=TCP_PORT, submitit_main_conf: dict=DEFAULT_SLURM_CONF_MAIN, submitit_collection_conf: dict=DEFAULT_SLURM_CONF):\n    self.num_jobs = num_jobs\n    self.backend = backend\n    self.framework = framework\n    self.submitit_collection_conf = submitit_collection_conf\n    self.submitit_main_conf = submitit_main_conf\n    self.tcpport = tcpport",
                    "docstring": "",
                    "description": ""
                }
            ]
        }
    ]
}
2024-12-11 14:56:42
'class DataCollectorBase' description: 
[blue]This class is a base implementation for data collectors in machine learning models, providing a foundation for collecting and storing data. It offers methods to update policy weights, iterate over the collected data, shut down the collector, set a seed for reproducibility, load state dictionaries, and load pre-trained models from saved state dictionaries.[/blue]
2024-12-11 14:57:09
'function update_policy_weights_' description: 
[blue]This function is used to update the weights of a policy in a reinforcement learning context, allowing for efficient and adaptive policy updates. It takes an optional parameter `policy_weights` which can be used to specify new weights for the policy, or it will use the existing weights if not provided. The function does not return any value, instead updating the internal state of the object it is called on.[/blue]
2024-12-11 14:57:28
'parameter policy_weights' description: 
[blue]This parameter is used to specify the weights assigned to each policy in a policy-based approach, allowing for customization of the model's behavior and decision-making process.[/blue]
2024-12-11 14:57:48
'function next' description: 
[blue]This function is used to move to the next item in a sequence or iterator, typically used when working with loops or iterating over data structures such as lists or generators. It advances the internal state of the object to point to the next element in the sequence, allowing for efficient iteration and processing of data.[/blue]
2024-12-11 14:58:07
'function shutdown' description: 
[blue]This function is used to initiate a shutdown process, likely terminating or closing various system resources, such as processes, connections, or applications, to bring the system to a safe state and prevent potential data loss or corruption.[/blue]
2024-12-11 14:58:24
'function iterator' description: 
[blue]This function is used to create an iterator for a TensorDictBase object, allowing it to be traversed and iterated over in a controlled manner.[/blue]
2024-12-11 14:58:47
'function set_seed' description: 
[blue]This function is used to initialize a random number generator with a specified seed value, allowing for reproducibility and control over the sequence of random numbers generated. The function takes an optional parameter 'static_seed' which defaults to False, indicating whether the seed should be set as static or not.[/blue]
2024-12-11 14:59:07
'parameter seed' description: 
[blue]This parameter is used to initialize the random number generator, allowing for reproducibility of results and enabling users to set a specific starting point for their random number generation.[/blue]
2024-12-11 14:59:27
'parameter static_seed' description: 
[blue]This parameter is used to enable or disable the use of a static seed for random number generation, allowing for reproducibility and deterministic behavior in simulations.[/blue]
2024-12-11 14:59:48
'function state_dict' description: 
[blue]This function is used to retrieve and return a dictionary representation of the model's state, which captures its current weights and other parameters. The returned dictionary can be used for serialization or loading purposes, allowing the model to be saved and restored at a later time.[/blue]
2024-12-11 15:00:15
'function load_state_dict' description: 
[blue]This function is used to load a pre-trained model's state dictionary into the current model instance, allowing for the restoration of previously trained weights and parameters. It takes an ordered dictionary containing the model's state as input and updates the internal state of the model with the loaded values, effectively reloading the model from a saved checkpoint or resume training from a previous point.[/blue]
2024-12-11 15:00:42
'parameter state_dict' description: 
[blue]This parameter is used to store and retrieve the model's state, which includes all the learned parameters and their values. It allows for saving and loading a trained model, enabling tasks such as model checkpointing, serialization, and deserialization. The state dictionary can be used to restore a model from a saved state, effectively reviving the model's weights and biases.[/blue]
2024-12-11 15:00:42
Total elapsed time (GenDescription Workflow): -5.998287077744802 min
2024-12-11 15:01:09
'function split_trajectories' description: 
[blue]This function is used to split a tensor dictionary representing trajectories into separate dictionaries based on specific keys. It allows for customization through the use of optional parameters such as prefix and trajectory_key, enabling flexible manipulation of the input data structure.[/blue]
2024-12-11 15:01:35
'parameter rollout_tensordict' description: 
[blue]This parameter is used to specify a tensor dictionary that will be used as the rollout strategy for the model. The rollout strategy determines how the model's weights are updated during training, and this parameter allows users to customize this process by providing their own tensor dictionary.[/blue]
2024-12-11 15:01:53
'parameter prefix' description: 
[blue]This parameter is used to specify a prefix for the output, which can be useful for formatting or logging purposes.[/blue]
2024-12-11 15:02:12
'parameter trajectory_key' description: 
[blue]This parameter is used to specify a unique key for the trajectory data, allowing it to be identified and accessed within the system.[/blue]
2024-12-11 15:02:32
'parameter done_key' description: 
[blue]This parameter is used to specify a unique key that indicates the completion of a task or operation, allowing for efficient tracking and management of progress.[/blue]
2024-12-11 15:02:57
'parameter as_nested' description: 
[blue]This parameter is used to specify whether the result should be returned as a nested dictionary or not. When set to True, the result will be wrapped in an additional level of nesting, with the outermost key being "result". If False (the default), the result will be returned without any extra nesting.[/blue]
2024-12-11 15:02:57
Total elapsed time (GenDescription Workflow): -2.242271971702576 min
2024-12-11 15:03:23
'class submitit_delayed_launcher' description: 
[blue]This class is a tool designed to manage and execute delayed submissions in a system, likely used for academic or competitive programming purposes. It provides an interface for launching programs with a specified delay between stages of the submission process. The class can be utilized to create a controlled environment where users can submit their code at a predetermined time, allowing for more organized and fair competition.[/blue]
2024-12-11 15:03:51
'function __init__' description: 
[blue]This function is used to initialize an instance of a class, setting its attributes and configuration parameters based on the provided arguments. It allows for customization of various settings such as the number of jobs, framework, backend, TCP port, and configuration dictionaries for submitit main and collection configurations.[/blue]
2024-12-11 15:04:13
'parameter num_jobs' description: 
[blue]This parameter is used to specify the number of worker processes to use when running a job. It allows for parallel processing and can significantly improve performance on multi-core systems by utilizing multiple CPU cores simultaneously.[/blue]
2024-12-11 15:04:37
'parameter framework' description: 
[blue]This parameter is used to specify the framework or architecture of a system, application, or project. It determines how the system will be structured and organized, including the tools, libraries, and technologies used. The value of this parameter can affect the overall performance, scalability, and maintainability of the system.[/blue]
2024-12-11 15:04:59
'parameter backend' description: 
[blue]This parameter is used to specify the backend framework or service that will be used for the application. The default value provided, "gloo", suggests that it may be related to a specific cloud-based platform or service.[/blue]
2024-12-11 15:05:17
'parameter tcpport' description: 
[blue]This parameter is used to specify the port number for TCP connections, allowing users to customize the communication protocol.[/blue]
2024-12-11 15:05:43
'parameter submitit_main_conf' description: 
[blue]This parameter is used to specify the configuration file for the Slurm main configuration, which controls the behavior of the Slurm job scheduler. When provided, this parameter overrides the default Slurm configuration and allows users to customize settings such as resource allocation, job scheduling, and more.[/blue]
2024-12-11 15:06:07
'parameter submitit_collection_conf' description: 
[blue]This parameter is used to configure the submission of a collection in Slurm, allowing users to customize various settings such as resource allocation and job scheduling. It provides an opportunity for users to tailor their submission process to meet specific requirements or preferences.[/blue]
2024-12-11 15:06:07
Total elapsed time (GenDescription Workflow): -3.16914834578832 min
2024-12-11 15:43:25
'class DataCollectorBase' description: 
[blue]This class is a base implementation for data collectors in machine learning models, providing a foundation for collecting and storing data. It offers methods to update policy weights, iterate over the collected data, shut down the collector, set a seed for reproducibility, load state dictionaries, and load pre-trained models from saved state dictionaries.[/blue]
2024-12-11 15:43:53
'function update_policy_weights_' description: 
[blue]This function is used to update the weights of a policy in a reinforcement learning context, allowing for efficient and adaptive policy updates. It takes an optional parameter `policy_weights` which can be used to specify new weights for the policy, or it will use the existing weights if not provided. The function does not return any value, instead updating the internal state of the object it is called on.[/blue]
2024-12-11 15:44:14
'parameter policy_weights' description: 
[blue]This parameter is used to specify the weights assigned to each policy in a policy-based approach, allowing for customization of the model's behavior and decision-making process.[/blue]
2024-12-11 15:44:37
'function next' description: 
[blue]This function is used to move to the next item in a sequence or iterator, typically used when working with loops or iterating over data structures such as lists or generators. It advances the internal state of the object to point to the next element in the sequence, allowing for efficient iteration and processing of data.[/blue]
2024-12-11 15:44:56
'function shutdown' description: 
[blue]This function is used to initiate a shutdown process, likely terminating or closing various system resources, such as processes, connections, or applications, to bring the system to a safe state and prevent potential data loss or corruption.[/blue]
2024-12-11 15:45:15
'function iterator' description: 
[blue]This function is used to create an iterator for a TensorDictBase object, allowing it to be traversed and iterated over in a controlled manner.[/blue]
2024-12-11 15:45:39
'function set_seed' description: 
[blue]This function is used to initialize a random number generator with a specified seed value, allowing for reproducibility and control over the sequence of random numbers generated. The function takes an optional parameter 'static_seed' which defaults to False, indicating whether the seed should be set as static or not.[/blue]
2024-12-11 15:46:01
'parameter seed' description: 
[blue]This parameter is used to initialize the random number generator, allowing for reproducibility of results and enabling users to set a specific starting point for their random number generation.[/blue]
2024-12-11 15:46:21
'parameter static_seed' description: 
[blue]This parameter is used to enable or disable the use of a static seed for random number generation, allowing for reproducibility and deterministic behavior in simulations.[/blue]
2024-12-11 15:46:46
'function state_dict' description: 
[blue]This function is used to retrieve and return a dictionary representation of the model's state, which captures its current weights and other parameters. The returned dictionary can be used for serialization or loading purposes, allowing the model to be saved and restored at a later time.[/blue]
2024-12-11 15:47:13
'function load_state_dict' description: 
[blue]This function is used to load a pre-trained model's state dictionary into the current model instance, allowing for the restoration of previously trained weights and parameters. It takes an ordered dictionary containing the model's state as input and updates the internal state of the model with the loaded values, effectively reloading the model from a saved checkpoint or resume training from a previous point.[/blue]
2024-12-11 15:47:41
'parameter state_dict' description: 
[blue]This parameter is used to store and retrieve the model's state, which includes all the learned parameters and their values. It allows for saving and loading a trained model, enabling tasks such as model checkpointing, serialization, and deserialization. The state dictionary can be used to restore a model from a saved state, effectively reviving the model's weights and biases.[/blue]
2024-12-11 15:47:41
Total elapsed time (GenDescription Workflow): 4.88109755118688 min
2024-12-11 15:52:14
'class DataCollectorBase' description: 
[blue]This class is a base implementation for data collectors in machine learning models, providing a foundation for collecting and storing data. It offers methods to update policy weights, iterate over the collected data, shut down the collector, set a seed for reproducibility, load state dictionaries, and load pre-trained models from saved state dictionaries.[/blue]
2024-12-11 15:52:42
'function update_policy_weights_' description: 
[blue]This function is used to update the weights of a policy in a reinforcement learning context, allowing for efficient and adaptive policy updates. It takes an optional parameter `policy_weights` which can be used to specify new weights for the policy, or it will use the existing weights if not provided. The function does not return any value, instead updating the internal state of the object it is called on.[/blue]
2024-12-11 15:53:03
'parameter policy_weights' description: 
[blue]This parameter is used to specify the weights assigned to each policy in a policy-based approach, allowing for customization of the model's behavior and decision-making process.[/blue]
2024-12-11 15:53:25
'function next' description: 
[blue]This function is used to move to the next item in a sequence or iterator, typically used when working with loops or iterating over data structures such as lists or generators. It advances the internal state of the object to point to the next element in the sequence, allowing for efficient iteration and processing of data.[/blue]
2024-12-11 15:53:44
'function shutdown' description: 
[blue]This function is used to initiate a shutdown process, likely terminating or closing various system resources, such as processes, connections, or applications, to bring the system to a safe state and prevent potential data loss or corruption.[/blue]
2024-12-11 15:54:02
'function iterator' description: 
[blue]This function is used to create an iterator for a TensorDictBase object, allowing it to be traversed and iterated over in a controlled manner.[/blue]
2024-12-11 15:54:25
'function set_seed' description: 
[blue]This function is used to initialize a random number generator with a specified seed value, allowing for reproducibility and control over the sequence of random numbers generated. The function takes an optional parameter 'static_seed' which defaults to False, indicating whether the seed should be set as static or not.[/blue]
2024-12-11 15:54:45
'parameter seed' description: 
[blue]This parameter is used to initialize the random number generator, allowing for reproducibility of results and enabling users to set a specific starting point for their random number generation.[/blue]
2024-12-11 15:55:05
'parameter static_seed' description: 
[blue]This parameter is used to enable or disable the use of a static seed for random number generation, allowing for reproducibility and deterministic behavior in simulations.[/blue]
2024-12-11 15:55:28
'function state_dict' description: 
[blue]This function is used to retrieve and return a dictionary representation of the model's state, which captures its current weights and other parameters. The returned dictionary can be used for serialization or loading purposes, allowing the model to be saved and restored at a later time.[/blue]
2024-12-11 15:55:55
'function load_state_dict' description: 
[blue]This function is used to load a pre-trained model's state dictionary into the current model instance, allowing for the restoration of previously trained weights and parameters. It takes an ordered dictionary containing the model's state as input and updates the internal state of the model with the loaded values, effectively reloading the model from a saved checkpoint or resume training from a previous point.[/blue]
2024-12-11 15:56:23
'parameter state_dict' description: 
[blue]This parameter is used to store and retrieve the model's state, which includes all the learned parameters and their values. It allows for saving and loading a trained model, enabling tasks such as model checkpointing, serialization, and deserialization. The state dictionary can be used to restore a model from a saved state, effectively reviving the model's weights and biases.[/blue]
2024-12-11 15:56:23
Total elapsed time (GenDescription Workflow): 4.676972933610281 min
2024-12-11 15:56:51
'function split_trajectories' description: 
[blue]This function is used to split a tensor dictionary representing trajectories into separate dictionaries based on specific keys. It allows for customization through the use of optional parameters such as prefix and trajectory_key, enabling flexible manipulation of the input data structure.[/blue]
2024-12-11 15:57:16
'parameter rollout_tensordict' description: 
[blue]This parameter is used to specify a tensor dictionary that will be used as the rollout strategy for the model. The rollout strategy determines how the model's weights are updated during training, and this parameter allows users to customize this process by providing their own tensor dictionary.[/blue]
2024-12-11 15:57:34
'parameter prefix' description: 
[blue]This parameter is used to specify a prefix for the output, which can be useful for formatting or logging purposes.[/blue]
2024-12-11 15:57:54
'parameter trajectory_key' description: 
[blue]This parameter is used to specify a unique key for the trajectory data, allowing it to be identified and accessed within the system.[/blue]
2024-12-11 15:58:13
'parameter done_key' description: 
[blue]This parameter is used to specify a unique key that indicates the completion of a task or operation, allowing for efficient tracking and management of progress.[/blue]
2024-12-11 15:58:39
'parameter as_nested' description: 
[blue]This parameter is used to specify whether the result should be returned as a nested dictionary or not. When set to True, the result will be wrapped in an additional level of nesting, with the outermost key being "result". If False (the default), the result will be returned without any extra nesting.[/blue]
2024-12-11 15:58:39
Total elapsed time (GenDescription Workflow): 2.2781035860379535 min
2024-12-11 15:59:06
'class submitit_delayed_launcher' description: 
[blue]This class is a tool designed to manage and execute delayed submissions in a system, likely used for academic or competitive programming purposes. It provides an interface for launching programs with a specified delay between stages of the submission process. The class can be utilized to create a controlled environment where users can submit their code at a predetermined time, allowing for more organized and fair competition.[/blue]
2024-12-11 15:59:34
'function __init__' description: 
[blue]This function is used to initialize an instance of a class, setting its attributes and configuration parameters based on the provided arguments. It allows for customization of various settings such as the number of jobs, framework, backend, TCP port, and configuration dictionaries for submitit main and collection configurations.[/blue]
2024-12-11 15:59:56
'parameter num_jobs' description: 
[blue]This parameter is used to specify the number of worker processes to use when running a job. It allows for parallel processing and can significantly improve performance on multi-core systems by utilizing multiple CPU cores simultaneously.[/blue]
2024-12-11 16:00:22
'parameter framework' description: 
[blue]This parameter is used to specify the framework or architecture of a system, application, or project. It determines how the system will be structured and organized, including the tools, libraries, and technologies used. The value of this parameter can affect the overall performance, scalability, and maintainability of the system.[/blue]
2024-12-11 16:00:43
'parameter backend' description: 
[blue]This parameter is used to specify the backend framework or service that will be used for the application. The default value provided, "gloo", suggests that it may be related to a specific cloud-based platform or service.[/blue]
2024-12-11 16:01:01
'parameter tcpport' description: 
[blue]This parameter is used to specify the port number for TCP connections, allowing users to customize the communication protocol.[/blue]
2024-12-11 16:01:27
'parameter submitit_main_conf' description: 
[blue]This parameter is used to specify the configuration file for the Slurm main configuration, which controls the behavior of the Slurm job scheduler. When provided, this parameter overrides the default Slurm configuration and allows users to customize settings such as resource allocation, job scheduling, and more.[/blue]
2024-12-11 16:01:51
'parameter submitit_collection_conf' description: 
[blue]This parameter is used to configure the submission of a collection in Slurm, allowing users to customize various settings such as resource allocation and job scheduling. It provides an opportunity for users to tailor their submission process to meet specific requirements or preferences.[/blue]
2024-12-11 16:01:51
Total elapsed time (GenDescription Workflow): 3.2033620635668436 min
2024-12-11 16:01:51
Total elapsed time (GenDescription Workflow): 10.159763288497924 min
