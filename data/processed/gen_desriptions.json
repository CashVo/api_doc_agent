{
    "collectors.py": [
        {
            "function_name": "recursive_map_to_cpu",
            "args": [
                {
                    "arg": "dictionary",
                    "description": "(OrderedDict) - The ordered dictionary to be mapped to CPU."
                }
            ],
            "signature": "recursive_map_to_cpu(dictionary: OrderedDict) -> OrderedDict",
            "function_code": "def recursive_map_to_cpu(dictionary: OrderedDict) -> OrderedDict:\n    \"\"\"Maps the tensors to CPU through a nested dictionary.\"\"\"\n    return OrderedDict(**{k: recursive_map_to_cpu(item) if isinstance(item, OrderedDict) else item.cpu() if isinstance(item, torch.Tensor) else item for k, item in dictionary.items()})",
            "description": "This function is used to recursively map PyTorch tensors and ordered dictionaries from the GPU to the CPU. It's significant for transferring models or data between devices, ensuring compatibility with different hardware configurations."
        },
        {
            "class_name": "DataCollectorBase",
            "bases": [
                "IterableDataset"
            ],
            "description": "This class is a base class for data collectors in PyTorch, providing a common interface for updating model weights and other state during training or testing. It allows for flexible customization of the data collection process through its methods, such as `update_policy_weights_` and `set_seed`, making it a crucial component in building robust and efficient machine learning pipelines.",
            "overview": "",
            "functions": [
                {
                    "function_name": "update_policy_weights_",
                    "args": [
                        {
                            "arg": "policy_weights",
                            "description": "(Optional[TensorDictBase]) - The policy weights to be updated. (default: None)"
                        },
                        {
                            "arg": "_",
                            "description": " (...) -> None"
                        }
                    ],
                    "signature": "update_policy_weights_(self, policy_weights: Optional[TensorDictBase]=None) -> None",
                    "function_code": "def update_policy_weights_(self, policy_weights: Optional[TensorDictBase]=None) -> None:\n    \"\"\"Updates the policy weights if the policy of the data collector and the trained policy live on different devices.\n\n        Args:\n            policy_weights (TensorDictBase, optional): if provided, a TensorDict containing\n                the weights of the policy to be used for the udpdate.\n\n        \"\"\"\n    if policy_weights is not None:\n        self.policy_weights.data.update_(policy_weights)\n    elif self.get_weights_fn is not None:\n        self.policy_weights.data.update_(self.get_weights_fn())",
                    "description": "This function is used to update the weights of a policy in PyTorch, ensuring consistency across devices when using data collectors and trained policies."
                },
                {
                    "function_name": "next",
                    "args": [
                        {
                            "arg": "None"
                        }
                    ],
                    "signature": "next(self)",
                    "function_code": "def next(self):\n    try:\n        if self._iterator is None:\n            self._iterator = iter(self)\n        out = next(self._iterator)\n        out.clear_device_()\n        return out\n    except StopIteration:\n        return None",
                    "description": "This function is used to retrieve the next item from an iterator, handling cases where the iterator has reached its end."
                },
                {
                    "function_name": "shutdown",
                    "args": [
                        {
                            "arg": "None"
                        }
                    ],
                    "signature": "shutdown(self)",
                    "function_code": "@abc.abstractmethod\ndef shutdown(self):\n    raise NotImplementedError",
                    "description": "This function is an abstract method that serves as a hook for customizing the shutdown process of a PyTorch module, allowing developers to implement specific cleanup actions before the module is unloaded."
                },
                {
                    "function_name": "iterator",
                    "args": [
                        {
                            "arg": "None"
                        }
                    ],
                    "signature": "iterator(self) -> Iterator[TensorDictBase]",
                    "function_code": "@abc.abstractmethod\ndef iterator(self) -> Iterator[TensorDictBase]:\n    raise NotImplementedError",
                    "description": "This function is an abstract base class method that defines the interface for creating an iterator over a TensorDict, allowing for iteration over its key-value pairs or values."
                },
                {
                    "function_name": "set_seed",
                    "args": [
                        {
                            "arg": "seed",
                            "description": " (int) - The random seed to be used. (default: None)"
                        },
                        {
                            "arg": "static_seed",
                            "description": " (bool) - Whether the static seed is used. (default: False)"
                        }
                    ],
                    "signature": "set_seed(self, seed: int, static_seed: bool=False) -> int",
                    "function_code": "@abc.abstractmethod\ndef set_seed(self, seed: int, static_seed: bool=False) -> int:\n    raise NotImplementedError",
                    "description": "This function is used to set a random seed for reproducibility in PyTorch models, ensuring that the same sequence of random numbers is generated during training and testing, thereby facilitating reliable comparisons and debugging."
                },
                {
                    "function_name": "state_dict",
                    "args": [
                        {
                            "arg": "None"
                        }
                    ],
                    "signature": "state_dict(self) -> OrderedDict",
                    "function_code": "@abc.abstractmethod\ndef state_dict(self) -> OrderedDict:\n    raise NotImplementedError",
                    "description": "This function is used to serialize and retrieve the model's weights and biases into a dictionary, allowing for easy saving and loading of the model's state."
                },
                {
                    "function_name": "load_state_dict",
                    "args": [
                        {
                            "arg": "state_dict",
                            "description": "(OrderedDict) - The model state dictionary to be loaded into the current state."
                        }
                    ],
                    "signature": "load_state_dict(self, state_dict: OrderedDict) -> None",
                    "function_code": "@abc.abstractmethod\ndef load_state_dict(self, state_dict: OrderedDict) -> None:\n    raise NotImplementedError",
                    "description": "This function is used to load the state dictionary of a PyTorch model from a given state dictionary, allowing for model checkpointing and resuming training from a saved state."
                }
            ]
        },
        {
            "class_name": "SyncDataCollector",
            "bases": [
                "DataCollectorBase"
            ],
            "description": "This class is a data collector used to synchronize and collect data from multiple workers in a distributed training setup, ensuring consistency across the model's parameters.",
            "overview": "",
            "functions": [
                {
                    "function_name": "__init__",
                    "args": [
                        {
                            "arg": "create_env_fn",
                            "description": "(Union[EnvBase, 'EnvCreator', Sequence[Callable[[], EnvBase]]]) - The function to create an environment. (default: None)"
                        },
                        {
                            "arg": "policy",
                            "description": "(Optional[Union[TensorDictModule, Callable[[TensorDictBase], TensorDictBase]]]) - The policy to be used. (default: None)"
                        },
                        {
                            "arg": "frames_per_batch",
                            "description": "(int) - The number of frames per batch. (default: -1)"
                        },
                        {
                            "arg": "total_frames",
                            "description": "(int) - The total number of frames. (default: -1)"
                        },
                        {
                            "arg": "device",
                            "description": "(DEVICE_TYPING) - The device to use for the environment. (default: None)"
                        },
                        {
                            "arg": "storing_device",
                            "description": "(DEVICE_TYPING) - The device to store the environment. (default: None)"
                        },
                        {
                            "arg": "policy_device",
                            "description": "(DEVICE_TYPING) - The device to use for the policy. (default: None)"
                        },
                        {
                            "arg": "env_device",
                            "description": "(DEVICE_TYPING) - The device to use for the environment. (default: None)"
                        },
                        {
                            "arg": "create_env_kwargs",
                            "description": "(dict | None) - The keyword arguments to pass to create_env_fn. (default: None)"
                        },
                        {
                            "arg": "max_frames_per_traj",
                            "description": "(int | None) - The maximum number of frames per trajectory. (default: None)"
                        },
                        {
                            "arg": "init_random_frames",
                            "description": "(int | None) - The initial random frames. (default: None)"
                        },
                        {
                            "arg": "reset_at_each_iter",
                            "description": "(bool) - Whether to reset at each iteration. (default: False)"
                        },
                        {
                            "arg": "postproc",
                            "description": "(Callable[[TensorDictBase], TensorDictBase] | None) - The post-processing function for the environment. (default: None)"
                        },
                        {
                            "arg": "split_trajs",
                            "description": "(bool | None) - Whether to split trajectories. (default: None)"
                        },
                        {
                            "arg": "exploration_type",
                            "description": "(ExplorationType=DEFAULT_EXPLORATION_TYPE) - The type of exploration to use."
                        },
                        {
                            "arg": "return_same_td",
                            "description": "(bool) - Whether to return the same TD. (default: False)"
                        },
                        {
                            "arg": "reset_when_done",
                            "description": "(bool) - Whether to reset when done. (default: True)"
                        },
                        {
                            "arg": "interruptor",
                            "description": "(None) - The interruptor."
                        },
                        {
                            "arg": "set_truncated",
                            "description": "(bool) - Whether to set truncated. (default: False)"
                        },
                        {
                            "arg": "use_buffers",
                            "description": "(bool | None) - Whether to use buffers. (default: None)"
                        },
                        {
                            "arg": "replay_buffer",
                            "description": "(ReplayBuffer | None) - The replay buffer."
                        },
                        {
                            "arg": "trust_policy",
                            "description": "(None) - The trust policy."
                        },
                        {
                            "arg": "compile_policy",
                            "description": "(bool | Dict[str, Any] | None) - Whether to compile the policy. (default: None)"
                        },
                        {
                            "arg": "cudagraph_policy",
                            "description": "(bool | Dict[str, Any] | None) - The cudagraph policy."
                        }
                    ],
                    "signature": "__init__(self, create_env_fn: Union[EnvBase, 'EnvCreator', Sequence[Callable[[], EnvBase]]], policy: Optional[Union[TensorDictModule, Callable[[TensorDictBase], TensorDictBase]]]=None, *, frames_per_batch: int, total_frames: int=-1, device: DEVICE_TYPING=None, storing_device: DEVICE_TYPING=None, policy_device: DEVICE_TYPING=None, env_device: DEVICE_TYPING=None, create_env_kwargs: dict | None=None, max_frames_per_traj: int | None=None, init_random_frames: int | None=None, reset_at_each_iter: bool=False, postproc: Callable[[TensorDictBase], TensorDictBase] | None=None, split_trajs: bool | None=None, exploration_type: ExplorationType=DEFAULT_EXPLORATION_TYPE, return_same_td: bool=False, reset_when_done: bool=True, interruptor=None, set_truncated: bool=False, use_buffers: bool | None=None, replay_buffer: ReplayBuffer | None=None, trust_policy: bool=None, compile_policy: bool | Dict[str, Any] | None=None, cudagraph_policy: bool | Dict[str, Any] | None=None, **kwargs)",
                    "function_code": "def __init__(self, create_env_fn: Union[EnvBase, 'EnvCreator', Sequence[Callable[[], EnvBase]]], policy: Optional[Union[TensorDictModule, Callable[[TensorDictBase], TensorDictBase]]]=None, *, frames_per_batch: int, total_frames: int=-1, device: DEVICE_TYPING=None, storing_device: DEVICE_TYPING=None, policy_device: DEVICE_TYPING=None, env_device: DEVICE_TYPING=None, create_env_kwargs: dict | None=None, max_frames_per_traj: int | None=None, init_random_frames: int | None=None, reset_at_each_iter: bool=False, postproc: Callable[[TensorDictBase], TensorDictBase] | None=None, split_trajs: bool | None=None, exploration_type: ExplorationType=DEFAULT_EXPLORATION_TYPE, return_same_td: bool=False, reset_when_done: bool=True, interruptor=None, set_truncated: bool=False, use_buffers: bool | None=None, replay_buffer: ReplayBuffer | None=None, trust_policy: bool=None, compile_policy: bool | Dict[str, Any] | None=None, cudagraph_policy: bool | Dict[str, Any] | None=None, **kwargs):\n    from torchrl.envs.batched_envs import BatchedEnvBase\n    self.closed = True\n    if create_env_kwargs is None:\n        create_env_kwargs = {}\n    if not isinstance(create_env_fn, EnvBase):\n        env = create_env_fn(**create_env_kwargs)\n    else:\n        env = create_env_fn\n        if create_env_kwargs:\n            if not isinstance(env, BatchedEnvBase):\n                raise RuntimeError(f\"kwargs were passed to SyncDataCollector but they can't be set on environment of type {type(create_env_fn)}.\")\n            env.update_kwargs(create_env_kwargs)\n    if policy is None:\n        policy = RandomPolicy(env.full_action_spec)\n    if trust_policy is None:\n        trust_policy = isinstance(policy, (RandomPolicy, CudaGraphModule))\n    self.trust_policy = trust_policy\n    self._read_compile_kwargs(compile_policy, cudagraph_policy)\n    self._traj_pool_val = kwargs.pop('traj_pool', None)\n    if kwargs:\n        raise TypeError(f'Keys {list(kwargs.keys())} are unknown to {type(self).__name__}.')\n    storing_device, policy_device, env_device = self._get_devices(storing_device=storing_device, policy_device=policy_device, env_device=env_device, device=device)\n    self.storing_device = storing_device\n    if self.storing_device is not None and self.storing_device.type != 'cuda':\n        if torch.cuda.is_available():\n            self._sync_storage = torch.cuda.synchronize\n        elif torch.backends.mps.is_available() and hasattr(torch, 'mps'):\n            self._sync_storage = torch.mps.synchronize\n        elif self.storing_device.type == 'cpu':\n            self._sync_storage = _do_nothing\n        else:\n            raise RuntimeError('Non supported device')\n    else:\n        self._sync_storage = _do_nothing\n    self.env_device = env_device\n    if self.env_device is not None and self.env_device.type != 'cuda':\n        if torch.cuda.is_available():\n            self._sync_env = torch.cuda.synchronize\n        elif torch.backends.mps.is_available() and hasattr(torch, 'mps'):\n            self._sync_env = torch.mps.synchronize\n        elif self.env_device.type == 'cpu':\n            self._sync_env = _do_nothing\n        else:\n            raise RuntimeError('Non supported device')\n    else:\n        self._sync_env = _do_nothing\n    self.policy_device = policy_device\n    if self.policy_device is not None and self.policy_device.type != 'cuda':\n        if torch.cuda.is_available():\n            self._sync_policy = torch.cuda.synchronize\n        elif torch.backends.mps.is_available() and hasattr(torch, 'mps'):\n            self._sync_policy = torch.mps.synchronize\n        elif self.policy_device.type == 'cpu':\n            self._sync_policy = _do_nothing\n        else:\n            raise RuntimeError('Non supported device')\n    else:\n        self._sync_policy = _do_nothing\n    self.device = device\n    self._cast_to_policy_device = self.policy_device != self.env_device\n    self.env: EnvBase = env\n    del env\n    self.replay_buffer = replay_buffer\n    if self.replay_buffer is not None:\n        if postproc is not None:\n            raise TypeError('postproc must be None when a replay buffer is passed.')\n        if use_buffers:\n            raise TypeError('replay_buffer is exclusive with use_buffers.')\n    if use_buffers is None:\n        use_buffers = not self.env._has_dynamic_specs and self.replay_buffer is None\n    self._use_buffers = use_buffers\n    self.replay_buffer = replay_buffer\n    self.closed = False\n    if not reset_when_done:\n        raise ValueError('reset_when_done is deprectated.')\n    self.reset_when_done = reset_when_done\n    self.n_env = self.env.batch_size.numel()\n    self.policy, self.get_weights_fn = self._get_policy_and_device(policy=policy, observation_spec=self.env.observation_spec)\n    if isinstance(self.policy, nn.Module):\n        self.policy_weights = TensorDict.from_module(self.policy, as_module=True)\n    else:\n        self.policy_weights = TensorDict()\n    if self.compiled_policy:\n        self.policy = torch.compile(self.policy, **self.compiled_policy_kwargs)\n    if self.cudagraphed_policy:\n        self.policy = CudaGraphModule(self.policy, **self.cudagraphed_policy_kwargs)\n    if self.env_device:\n        self.env: EnvBase = self.env.to(self.env_device)\n    elif self.env.device is not None:\n        self.env_device = self.env.device\n    self._cast_to_env_device = self._cast_to_policy_device or self.env.device != self.storing_device\n    self.max_frames_per_traj = int(max_frames_per_traj) if max_frames_per_traj is not None else 0\n    if self.max_frames_per_traj is not None and self.max_frames_per_traj > 0:\n        for key in self.env.output_spec.keys(True, True):\n            if isinstance(key, str):\n                key = (key,)\n            if 'step_count' in key:\n                raise ValueError(\"A 'step_count' key is already present in the environment and the 'max_frames_per_traj' argument may conflict with a 'StepCounter' that has already been set. Possible solutions: Set max_frames_per_traj to 0 or remove the StepCounter limit from the environment transforms.\")\n        self.env = TransformedEnv(self.env, StepCounter(max_steps=self.max_frames_per_traj))\n    if total_frames is None or total_frames < 0:\n        total_frames = float('inf')\n    else:\n        remainder = total_frames % frames_per_batch\n        if remainder != 0 and RL_WARNINGS:\n            warnings.warn(f'total_frames ({total_frames}) is not exactly divisible by frames_per_batch ({frames_per_batch}).This means {frames_per_batch - remainder} additional frames will be collected.To silence this message, set the environment variable RL_WARNINGS to False.')\n    self.total_frames = int(total_frames) if total_frames != float('inf') else total_frames\n    self.reset_at_each_iter = reset_at_each_iter\n    self.init_random_frames = int(init_random_frames) if init_random_frames is not None else 0\n    if init_random_frames is not None and init_random_frames % frames_per_batch != 0 and RL_WARNINGS:\n        warnings.warn(f'init_random_frames ({init_random_frames}) is not exactly a multiple of frames_per_batch ({frames_per_batch}),  this results in more init_random_frames than requested ({-(-init_random_frames // frames_per_batch) * frames_per_batch}).To silence this message, set the environment variable RL_WARNINGS to False.')\n    self.postproc = postproc\n    if self.postproc is not None and hasattr(self.postproc, 'to') and self.storing_device:\n        self.postproc.to(self.storing_device)\n    if frames_per_batch % self.n_env != 0 and RL_WARNINGS:\n        warnings.warn(f'frames_per_batch ({frames_per_batch}) is not exactly divisible by the number of batched environments ({self.n_env}),  this results in more frames_per_batch per iteration that requested ({-(-frames_per_batch // self.n_env) * self.n_env}).To silence this message, set the environment variable RL_WARNINGS to False.')\n    self.requested_frames_per_batch = int(frames_per_batch)\n    self.frames_per_batch = -(-frames_per_batch // self.n_env)\n    self.exploration_type = exploration_type if exploration_type else DEFAULT_EXPLORATION_TYPE\n    self.return_same_td = return_same_td\n    self.set_truncated = set_truncated\n    self._make_shuttle()\n    if self._use_buffers:\n        self._make_final_rollout()\n    self._set_truncated_keys()\n    if split_trajs is None:\n        split_trajs = False\n    self.split_trajs = split_trajs\n    self._exclude_private_keys = True\n    self.interruptor = interruptor\n    self._frames = 0\n    self._iter = -1",
                    "description": "This function is the constructor for a class that initializes various attributes and settings for an environment, policy, and rollout. It takes in numerous keyword arguments to customize its behavior, including batch size, frames per batch, total frames, exploration type, and more. The class appears to be designed for reinforcement learning tasks, particularly those involving batched environments and policies."
                },
                {
                    "function_name": "next",
                    "args": [
                        {
                            "arg": "None"
                        }
                    ],
                    "signature": "next(self)",
                    "function_code": "def next(self):\n    return super().next()",
                    "description": "This function is a placeholder that delegates to the parent class's `next` method, effectively bypassing any custom implementation. It should be used when you want to maintain the default behavior of the parent class while still providing a consistent interface for subclasses."
                },
                {
                    "function_name": "update_policy_weights_",
                    "args": [
                        {
                            "arg": "policy_weights",
                            "description": "(Optional[TensorDictBase]) - The policy weights to be updated. (default: None)"
                        },
                        {
                            "arg": "_",
                            "description": " (...) -> None"
                        }
                    ],
                    "signature": "update_policy_weights_(self, policy_weights: Optional[TensorDictBase]=None) -> None",
                    "function_code": "def update_policy_weights_(self, policy_weights: Optional[TensorDictBase]=None) -> None:\n    super().update_policy_weights_(policy_weights)",
                    "description": "This function is a method that updates the weights of a policy in a reinforcement learning model by calling the parent class's `update_policy_weights_` method."
                },
                {
                    "function_name": "set_seed",
                    "args": [
                        {
                            "arg": "seed",
                            "description": " (int) - The random seed to be used. (default: None)"
                        },
                        {
                            "arg": "static_seed",
                            "description": " (bool) - Whether the static seed is used. (default: False)"
                        }
                    ],
                    "signature": "set_seed(self, seed: int, static_seed: bool=False) -> int",
                    "function_code": "def set_seed(self, seed: int, static_seed: bool=False) -> int:\n    \"\"\"Sets the seeds of the environments stored in the DataCollector.\n\n        Args:\n            seed (int): integer representing the seed to be used for the environment.\n            static_seed(bool, optional): if ``True``, the seed is not incremented.\n                Defaults to False\n\n        Returns:\n            Output seed. This is useful when more than one environment is contained in the DataCollector, as the\n            seed will be incremented for each of these. The resulting seed is the seed of the last environment.\n\n        Examples:\n            >>> from torchrl.envs import ParallelEnv\n            >>> from torchrl.envs.libs.gym import GymEnv\n            >>> from tensordict.nn import TensorDictModule\n            >>> from torch import nn\n            >>> env_fn = lambda: GymEnv(\"Pendulum-v1\")\n            >>> env_fn_parallel = ParallelEnv(6, env_fn)\n            >>> policy = TensorDictModule(nn.Linear(3, 1), in_keys=[\"observation\"], out_keys=[\"action\"])\n            >>> collector = SyncDataCollector(env_fn_parallel, policy, total_frames=300, frames_per_batch=100)\n            >>> out_seed = collector.set_seed(1)  # out_seed = 6\n\n        \"\"\"\n    out = self.env.set_seed(seed, static_seed=static_seed)\n    return out",
                    "description": "This function is used to set the seeds for environments in a DataCollector, allowing for reproducibility and incrementing of seeds across multiple environments."
                },
                {
                    "function_name": "iterator",
                    "args": [
                        {
                            "arg": "None"
                        }
                    ],
                    "signature": "iterator(self) -> Iterator[TensorDictBase]",
                    "function_code": "def iterator(self) -> Iterator[TensorDictBase]:\n    \"\"\"Iterates through the DataCollector.\n\n        Yields: TensorDictBase objects containing (chunks of) trajectories\n\n        \"\"\"\n    if self.storing_device and self.storing_device.type == 'cuda':\n        stream = torch.cuda.Stream(self.storing_device, priority=-1)\n        event = stream.record_event()\n        streams = [stream]\n        events = [event]\n    elif self.storing_device is None:\n        streams = []\n        events = []\n        cuda_devices = set()\n\n        def cuda_check(tensor: torch.Tensor):\n            if tensor.is_cuda:\n                cuda_devices.add(tensor.device)\n        if not self._use_buffers:\n            for spec in self.env.specs.values(True, True):\n                if spec.device.type == 'cuda':\n                    if ':' not in str(spec.device):\n                        raise RuntimeError(\"A cuda spec did not have a device associated. Make sure to pass `'cuda:device_num'` to each spec device.\")\n                    cuda_devices.add(spec.device)\n        else:\n            self._final_rollout.apply(cuda_check, filter_empty=True)\n        for device in cuda_devices:\n            streams.append(torch.cuda.Stream(device, priority=-1))\n            events.append(streams[-1].record_event())\n    else:\n        streams = []\n        events = []\n    with contextlib.ExitStack() as stack:\n        for stream in streams:\n            stack.enter_context(torch.cuda.stream(stream))\n        while self._frames < self.total_frames:\n            self._iter += 1\n            tensordict_out = self.rollout()\n            if tensordict_out is None:\n                yield\n                continue\n            self._increment_frames(tensordict_out.numel())\n            if self.split_trajs:\n                tensordict_out = split_trajectories(tensordict_out, prefix='collector')\n            if self.postproc is not None:\n                tensordict_out = self.postproc(tensordict_out)\n            if self._exclude_private_keys:\n\n                def is_private(key):\n                    if isinstance(key, str) and key.startswith('_'):\n                        return True\n                    if isinstance(key, tuple) and any((_key.startswith('_') for _key in key)):\n                        return True\n                    return False\n                excluded_keys = [key for key in tensordict_out.keys(True) if is_private(key)]\n                tensordict_out = tensordict_out.exclude(*excluded_keys, inplace=True)\n            if self.return_same_td:\n                if events:\n                    for event in events:\n                        event.record()\n                        event.synchronize()\n                yield tensordict_out\n            else:\n                yield tensordict_out.clone()",
                    "description": "This function is used to iterate through a DataCollector, yielding TensorDictBase objects containing chunks of trajectories. It manages CUDA streams and events for efficient data collection on GPU devices."
                },
                {
                    "function_name": "rollout",
                    "args": [
                        {
                            "arg": "None"
                        }
                    ],
                    "signature": "rollout(self) -> TensorDictBase",
                    "function_code": "@torch.no_grad()\ndef rollout(self) -> TensorDictBase:\n    \"\"\"Computes a rollout in the environment using the provided policy.\n\n        Returns:\n            TensorDictBase containing the computed rollout.\n\n        \"\"\"\n    if self.reset_at_each_iter:\n        self._shuttle.update(self.env.reset())\n    if self._use_buffers:\n        self._final_rollout.fill_(('collector', 'traj_ids'), -1)\n    else:\n        pass\n    tensordicts = []\n    with set_exploration_type(self.exploration_type):\n        for t in range(self.frames_per_batch):\n            if self.init_random_frames is not None and self._frames < self.init_random_frames:\n                self.env.rand_action(self._shuttle)\n            else:\n                if self._cast_to_policy_device:\n                    if self.policy_device is not None:\n                        policy_input = self._shuttle.to(self.policy_device, non_blocking=True)\n                        self._sync_policy()\n                    elif self.policy_device is None:\n                        policy_input = self._shuttle\n                else:\n                    policy_input = self._shuttle\n                policy_output = self.policy(policy_input)\n                if self._shuttle is not policy_output:\n                    self._shuttle.update(policy_output, keys_to_update=self._policy_output_keys)\n            if self._cast_to_env_device:\n                if self.env_device is not None:\n                    env_input = self._shuttle.to(self.env_device, non_blocking=True)\n                    self._sync_env()\n                elif self.env_device is None:\n                    env_input = self._shuttle\n            else:\n                env_input = self._shuttle\n            env_output, env_next_output = self.env.step_and_maybe_reset(env_input)\n            if self._shuttle is not env_output:\n                next_data = env_output.get('next')\n                if self._shuttle_has_no_device:\n                    next_data.clear_device_()\n                self._shuttle.set('next', next_data)\n            if self.replay_buffer is not None:\n                self.replay_buffer.add(self._shuttle)\n                if self._increment_frames(self._shuttle.numel()):\n                    return\n            elif self.storing_device is not None:\n                tensordicts.append(self._shuttle.to(self.storing_device, non_blocking=True))\n                self._sync_storage()\n            else:\n                tensordicts.append(self._shuttle)\n            collector_data = self._shuttle.get('collector').copy()\n            self._shuttle = env_next_output\n            if self._shuttle_has_no_device:\n                self._shuttle.clear_device_()\n            self._shuttle.set('collector', collector_data)\n            self._update_traj_ids(env_output)\n            if self.interruptor is not None and self.interruptor.collection_stopped():\n                if self.replay_buffer is not None:\n                    return\n                result = self._final_rollout\n                if self._use_buffers:\n                    try:\n                        torch.stack(tensordicts, self._final_rollout.ndim - 1, out=self._final_rollout[..., :t + 1])\n                    except RuntimeError:\n                        with self._final_rollout.unlock_():\n                            torch.stack(tensordicts, self._final_rollout.ndim - 1, out=self._final_rollout[..., :t + 1])\n                else:\n                    result = TensorDict.maybe_dense_stack(tensordicts, dim=-1)\n                break\n        else:\n            if self._use_buffers:\n                result = self._final_rollout\n                try:\n                    result = torch.stack(tensordicts, self._final_rollout.ndim - 1, out=self._final_rollout)\n                except RuntimeError:\n                    with self._final_rollout.unlock_():\n                        result = torch.stack(tensordicts, self._final_rollout.ndim - 1, out=self._final_rollout)\n            elif self.replay_buffer is not None:\n                return\n            else:\n                result = TensorDict.maybe_dense_stack(tensordicts, dim=-1)\n                result.refine_names(..., 'time')\n    return self._maybe_set_truncated(result)",
                    "description": "This function is used to generate a rollout in the environment using the provided policy. It returns a TensorDictBase containing the computed rollout and can be used for training reinforcement learning agents by sampling multiple rollouts from the same policy and averaging their outputs."
                },
                {
                    "function_name": "reset",
                    "args": [
                        {
                            "arg": "index",
                            "description": "(int or tuple of ints) - The index at which to reset the model state."
                        },
                        {
                            "arg": "kwargs",
                            "description": " (*) - Additional keyword arguments. (default: None)"
                        }
                    ],
                    "signature": "reset(self, index=None, **kwargs) -> None",
                    "function_code": "@torch.no_grad()\ndef reset(self, index=None, **kwargs) -> None:\n    \"\"\"Resets the environments to a new initial state.\"\"\"\n    collector_metadata = self._shuttle.get('collector').clone()\n    if index is not None:\n        if prod(self.env.batch_size) == 0:\n            raise RuntimeError('resetting unique env with index is not permitted.')\n        for reset_key, done_keys in zip(self.env.reset_keys, self.env.done_keys_groups):\n            _reset = torch.zeros(self.env.full_done_spec[done_keys[0]].shape, dtype=torch.bool, device=self.env.device)\n            _reset[index] = 1\n            self._shuttle.set(reset_key, _reset)\n    else:\n        _reset = None\n        self._shuttle.zero_()\n    self._shuttle.update(self.env.reset(**kwargs), inplace=True)\n    collector_metadata['traj_ids'] = collector_metadata['traj_ids'] - collector_metadata['traj_ids'].min()\n    self._shuttle['collector'] = collector_metadata",
                    "description": "This function is used to reset environments in a PyTorch environment, updating the internal state and metadata accordingly."
                },
                {
                    "function_name": "shutdown",
                    "args": [
                        {
                            "arg": "None"
                        }
                    ],
                    "signature": "shutdown(self) -> None",
                    "function_code": "def shutdown(self) -> None:\n    \"\"\"Shuts down all workers and/or closes the local environment.\"\"\"\n    if not self.closed:\n        self.closed = True\n        del self._shuttle\n        if self._use_buffers:\n            del self._final_rollout\n        if not self.env.is_closed:\n            self.env.close()\n        del self.env\n    return",
                    "description": "This function is used to cleanly shut down a PyTorch environment, releasing system resources and ensuring proper cleanup."
                },
                {
                    "function_name": "state_dict",
                    "args": [
                        {
                            "arg": "None"
                        }
                    ],
                    "signature": "state_dict(self) -> OrderedDict",
                    "function_code": "def state_dict(self) -> OrderedDict:\n    \"\"\"Returns the local state_dict of the data collector (environment and policy).\n\n        Returns:\n            an ordered dictionary with fields :obj:`\"policy_state_dict\"` and\n            `\"env_state_dict\"`.\n\n        \"\"\"\n    from torchrl.envs.batched_envs import BatchedEnvBase\n    if isinstance(self.env, TransformedEnv):\n        env_state_dict = self.env.transform.state_dict()\n    elif isinstance(self.env, BatchedEnvBase):\n        env_state_dict = self.env.state_dict()\n    else:\n        env_state_dict = OrderedDict()\n    if hasattr(self.policy, 'state_dict'):\n        policy_state_dict = self.policy.state_dict()\n        state_dict = OrderedDict(policy_state_dict=policy_state_dict, env_state_dict=env_state_dict)\n    else:\n        state_dict = OrderedDict(env_state_dict=env_state_dict)\n    state_dict.update({'frames': self._frames, 'iter': self._iter})\n    return state_dict",
                    "description": "This function is used to retrieve and combine the local state dictionaries of an environment and a policy in PyTorch RL. It returns an ordered dictionary containing both environment and policy state dictionaries, along with additional metadata such as frames and iteration number."
                },
                {
                    "function_name": "load_state_dict",
                    "args": [
                        {
                            "arg": "state_dict",
                            "description": "(OrderedDict) - The model state dictionary to be loaded into the current state."
                        },
                        {
                            "arg": "kwargs",
                            "description": " (Any) - Additional keyword arguments. (default: None)"
                        }
                    ],
                    "signature": "load_state_dict(self, state_dict: OrderedDict, **kwargs) -> None",
                    "function_code": "def load_state_dict(self, state_dict: OrderedDict, **kwargs) -> None:\n    \"\"\"Loads a state_dict on the environment and policy.\n\n        Args:\n            state_dict (OrderedDict): ordered dictionary containing the fields\n                `\"policy_state_dict\"` and :obj:`\"env_state_dict\"`.\n\n        \"\"\"\n    strict = kwargs.get('strict', True)\n    if strict or 'env_state_dict' in state_dict:\n        self.env.load_state_dict(state_dict['env_state_dict'], **kwargs)\n    if strict or 'policy_state_dict' in state_dict:\n        self.policy.load_state_dict(state_dict['policy_state_dict'], **kwargs)\n    self._frames = state_dict['frames']\n    self._iter = state_dict['iter']",
                    "description": "This function is used to load a pre-trained model's state dictionary into the environment and policy, allowing for the resumption of training or inference from a previously saved checkpoint."
                }
            ]
        },
        {
            "class_name": "MultiSyncDataCollector",
            "bases": [
                "_MultiDataCollector"
            ],
            "description": "This class is a PyTorch data collector that synchronizes and batches data across multiple workers, ensuring consistent data distribution for training and evaluation.",
            "overview": "",
            "functions": [
                {
                    "function_name": "next",
                    "args": [
                        {
                            "arg": "None"
                        }
                    ],
                    "signature": "next(self)",
                    "function_code": "def next(self):\n    return super().next()",
                    "description": "This function is a placeholder that delegates to the parent class's `next` method, effectively bypassing any custom implementation. It should be used when you want to maintain the default behavior of the parent class while still providing a consistent interface for subclasses."
                },
                {
                    "function_name": "shutdown",
                    "args": [
                        {
                            "arg": "None"
                        }
                    ],
                    "signature": "shutdown(self)",
                    "function_code": "def shutdown(self):\n    if hasattr(self, 'out_buffer'):\n        del self.out_buffer\n    if hasattr(self, 'buffers'):\n        del self.buffers\n    return super().shutdown()",
                    "description": "This function is used to release resources held by a PyTorch model during shutdown, ensuring memory safety and preventing potential memory leaks."
                },
                {
                    "function_name": "set_seed",
                    "args": [
                        {
                            "arg": "seed",
                            "description": " (int) - The random seed to be used. (default: None)"
                        },
                        {
                            "arg": "static_seed",
                            "description": " (bool) - Whether the static seed is used. (default: False)"
                        }
                    ],
                    "signature": "set_seed(self, seed: int, static_seed: bool=False) -> int",
                    "function_code": "def set_seed(self, seed: int, static_seed: bool=False) -> int:\n    return super().set_seed(seed, static_seed)",
                    "description": "This function is used to set a random seed for reproducibility in PyTorch models. It ensures that the same sequence of random numbers is generated every time the model is run with the same seed value, making it easier to debug and test models."
                },
                {
                    "function_name": "state_dict",
                    "args": [
                        {
                            "arg": "None"
                        }
                    ],
                    "signature": "state_dict(self) -> OrderedDict",
                    "function_code": "def state_dict(self) -> OrderedDict:\n    return super().state_dict()",
                    "description": "This function is used to retrieve the model's state dictionary, which contains the learned parameters and their values, allowing for model loading and saving."
                },
                {
                    "function_name": "load_state_dict",
                    "args": [
                        {
                            "arg": "state_dict",
                            "description": "(OrderedDict) - The model state dictionary to be loaded into the current state."
                        }
                    ],
                    "signature": "load_state_dict(self, state_dict: OrderedDict) -> None",
                    "function_code": "def load_state_dict(self, state_dict: OrderedDict) -> None:\n    return super().load_state_dict(state_dict)",
                    "description": "This function is used to load the state dictionary of a PyTorch model from an existing checkpoint or saved model. It allows for the transfer of learned parameters and other model state between different runs or environments, enabling faster development and deployment."
                },
                {
                    "function_name": "update_policy_weights_",
                    "args": [
                        {
                            "arg": "policy_weights",
                            "description": "(Optional[TensorDictBase]) - The policy weights to be updated. (default: None)"
                        },
                        {
                            "arg": "_",
                            "description": " (...) -> None"
                        }
                    ],
                    "signature": "update_policy_weights_(self, policy_weights: Optional[TensorDictBase]=None) -> None",
                    "function_code": "def update_policy_weights_(self, policy_weights: Optional[TensorDictBase]=None) -> None:\n    super().update_policy_weights_(policy_weights)",
                    "description": "This function is a method that updates the weights of a policy in a reinforcement learning model by calling the parent class's `update_policy_weights_` method."
                },
                {
                    "function_name": "frames_per_batch_worker",
                    "args": [
                        {
                            "arg": "None"
                        }
                    ],
                    "signature": "frames_per_batch_worker(self)",
                    "function_code": "@property\ndef frames_per_batch_worker(self):\n    if self.requested_frames_per_batch % self.num_workers != 0 and RL_WARNINGS:\n        warnings.warn(f'frames_per_batch {self.requested_frames_per_batch} is not exactly divisible by the number of collector workers {self.num_workers}, this results in more frames_per_batch per iteration that requested.To silence this message, set the environment variable RL_WARNINGS to False.')\n    frames_per_batch_worker = -(-self.requested_frames_per_batch // self.num_workers)\n    return frames_per_batch_worker",
                    "description": "This function is used to calculate the effective `frames_per_batch` value for a batch of frames when using multiple collector workers, ensuring that the requested FPS is achieved despite the increased number of frames per iteration."
                },
                {
                    "function_name": "iterator",
                    "args": [
                        {
                            "arg": "None"
                        }
                    ],
                    "signature": "iterator(self) -> Iterator[TensorDictBase]",
                    "function_code": "def iterator(self) -> Iterator[TensorDictBase]:\n    cat_results = self.cat_results\n    if cat_results is None:\n        cat_results = 'stack'\n    self.buffers = {}\n    dones = [False for _ in range(self.num_workers)]\n    workers_frames = [0 for _ in range(self.num_workers)]\n    same_device = None\n    self.out_buffer = None\n    preempt = self.interruptor is not None and self.preemptive_threshold < 1.0\n    while not all(dones) and self._frames < self.total_frames:\n        _check_for_faulty_process(self.procs)\n        if self.update_at_each_batch:\n            self.update_policy_weights_()\n        for idx in range(self.num_workers):\n            if self.init_random_frames is not None and self._frames < self.init_random_frames:\n                msg = 'continue_random'\n            else:\n                msg = 'continue'\n            self.pipes[idx].send((None, msg))\n        self._iter += 1\n        if preempt:\n            self.interruptor.start_collection()\n            while self.queue_out.qsize() < int(self.num_workers * self.preemptive_threshold):\n                continue\n            self.interruptor.stop_collection()\n            while self.queue_out.qsize() < int(self.num_workers):\n                continue\n        for _ in range(self.num_workers):\n            new_data, j = self.queue_out.get()\n            use_buffers = self._use_buffers\n            if self.replay_buffer is not None:\n                idx = new_data\n                workers_frames[idx] = workers_frames[idx] + self.frames_per_batch_worker\n                continue\n            elif j == 0 or not use_buffers:\n                try:\n                    data, idx = new_data\n                    self.buffers[idx] = data\n                    if use_buffers is None and j > 0:\n                        self._use_buffers = False\n                except TypeError:\n                    if use_buffers is None:\n                        self._use_buffers = True\n                        idx = new_data\n                    else:\n                        raise\n            else:\n                idx = new_data\n            if preempt:\n                if cat_results != 'stack':\n                    buffers = {}\n                    for idx, buffer in self.buffers.items():\n                        valid = buffer.get(('collector', 'traj_ids')) != -1\n                        if valid.ndim > 2:\n                            valid = valid.flatten(0, -2)\n                        if valid.ndim == 2:\n                            valid = valid.any(0)\n                        buffers[idx] = buffer[..., valid]\n                else:\n                    for buffer in self.buffers.values():\n                        with buffer.unlock_():\n                            buffer.set(('collector', 'mask'), buffer.get(('collector', 'traj_ids')) != -1)\n                    buffers = self.buffers\n            else:\n                buffers = self.buffers\n            workers_frames[idx] = workers_frames[idx] + buffers[idx].numel()\n            if workers_frames[idx] >= self.total_frames:\n                dones[idx] = True\n        if self.replay_buffer is not None:\n            yield\n            self._frames += self.frames_per_batch_worker * self.num_workers\n            continue\n        n_collected = 0\n        for idx in range(self.num_workers):\n            buffer = buffers[idx]\n            traj_ids = buffer.get(('collector', 'traj_ids'))\n            if preempt:\n                if cat_results == 'stack':\n                    mask_frames = buffer.get(('collector', 'traj_ids')) != -1\n                    n_collected += mask_frames.sum().cpu()\n                else:\n                    n_collected += traj_ids.numel()\n            else:\n                n_collected += traj_ids.numel()\n        if same_device is None:\n            prev_device = None\n            same_device = True\n            for item in self.buffers.values():\n                if prev_device is None:\n                    prev_device = item.device\n                else:\n                    same_device = same_device and item.device == prev_device\n        if cat_results == 'stack':\n            stack = torch.stack if self._use_buffers else TensorDict.maybe_dense_stack\n            if same_device:\n                self.out_buffer = stack(list(buffers.values()), 0)\n            else:\n                self.out_buffer = stack([item.cpu() for item in buffers.values()], 0)\n        else:\n            if self._use_buffers is None:\n                torchrl_logger.warning('use_buffer not specified and not yet inferred from data, assuming `True`.')\n            elif not self._use_buffers:\n                raise RuntimeError('Cannot concatenate results with use_buffers=False')\n            try:\n                if same_device:\n                    self.out_buffer = torch.cat(list(buffers.values()), cat_results)\n                else:\n                    self.out_buffer = torch.cat([item.cpu() for item in buffers.values()], cat_results)\n            except RuntimeError as err:\n                if preempt and cat_results != -1 and ('Sizes of tensors must match' in str(err)):\n                    raise RuntimeError(\"The value provided to cat_results isn't compatible with the collectors outputs. Consider using `cat_results=-1`.\")\n                raise\n        if self.split_trajs:\n            out = split_trajectories(self.out_buffer, prefix='collector')\n        else:\n            out = self.out_buffer\n        if cat_results in (-1, 'stack'):\n            out.refine_names(*[None] * (out.ndim - 1) + ['time'])\n        self._frames += n_collected\n        if self.postprocs:\n            self.postprocs = self.postprocs.to(out.device)\n            out = self.postprocs(out)\n        if self._exclude_private_keys:\n            excluded_keys = [key for key in out.keys() if key.startswith('_')]\n            if excluded_keys:\n                out = out.exclude(*excluded_keys)\n        yield out\n        del out\n    del self.buffers\n    self.out_buffer = None",
                    "description": "This function is a PyTorch iterator that generates batches of data from a collection of buffers, applying various transformations and filtering criteria along the way. It's used to process and combine data from multiple workers in a distributed environment, yielding a batched output for further processing or training."
                }
            ]
        },
        {
            "class_name": "MultiaSyncDataCollector",
            "bases": [
                "_MultiDataCollector"
            ],
            "description": "This class is a data collector for multi-agent environments, designed to collect and store experiences from multiple agents in parallel, allowing for efficient training of multi-agent reinforcement learning models.",
            "overview": "",
            "functions": [
                {
                    "function_name": "__init__",
                    "args": [
                        {
                            "arg": "None"
                        }
                    ],
                    "signature": "__init__(self, *args, **kwargs)",
                    "function_code": "def __init__(self, *args, **kwargs):\n    super().__init__(*args, **kwargs)\n    self.out_tensordicts = defaultdict(lambda: None)\n    self.running = False\n    if self.postprocs is not None:\n        postproc = self.postprocs\n        self.postprocs = {}\n        for _device in self.storing_device:\n            if _device not in self.postprocs:\n                self.postprocs[_device] = deepcopy(postproc).to(_device)",
                    "description": "This function is a special method in PyTorch classes that initializes the object's attributes when an instance of the class is created. It should be used to set up the initial state of the object, including any necessary computations or data structures, and is typically called automatically when an instance of the class is created."
                },
                {
                    "function_name": "next",
                    "args": [
                        {
                            "arg": "None"
                        }
                    ],
                    "signature": "next(self)",
                    "function_code": "def next(self):\n    return super().next()",
                    "description": "This function is a placeholder that delegates to the parent class's `next` method, effectively bypassing any custom implementation. It should be used when you want to maintain the default behavior of the parent class while still providing a consistent interface for subclasses."
                },
                {
                    "function_name": "shutdown",
                    "args": [
                        {
                            "arg": "None"
                        }
                    ],
                    "signature": "shutdown(self)",
                    "function_code": "def shutdown(self):\n    if hasattr(self, 'out_tensordicts'):\n        del self.out_tensordicts\n    return super().shutdown()",
                    "description": "This function is used to clean up resources and finalize the shutdown of a PyTorch model or module instance before calling its parent class's `shutdown` method."
                },
                {
                    "function_name": "set_seed",
                    "args": [
                        {
                            "arg": "seed",
                            "description": " (int) - The random seed to be used. (default: None)"
                        },
                        {
                            "arg": "static_seed",
                            "description": " (bool) - Whether the static seed is used. (default: False)"
                        }
                    ],
                    "signature": "set_seed(self, seed: int, static_seed: bool=False) -> int",
                    "function_code": "def set_seed(self, seed: int, static_seed: bool=False) -> int:\n    return super().set_seed(seed, static_seed)",
                    "description": "This function is used to set a random seed for reproducibility in PyTorch models. It ensures that the same sequence of random numbers is generated every time the model is run with the same seed value, making it easier to debug and test models."
                },
                {
                    "function_name": "state_dict",
                    "args": [
                        {
                            "arg": "None"
                        }
                    ],
                    "signature": "state_dict(self) -> OrderedDict",
                    "function_code": "def state_dict(self) -> OrderedDict:\n    return super().state_dict()",
                    "description": "This function is used to retrieve the model's state dictionary, which contains the learned parameters and their values, allowing for model loading and saving."
                },
                {
                    "function_name": "load_state_dict",
                    "args": [
                        {
                            "arg": "state_dict",
                            "description": "(OrderedDict) - The model state dictionary to be loaded into the current state."
                        }
                    ],
                    "signature": "load_state_dict(self, state_dict: OrderedDict) -> None",
                    "function_code": "def load_state_dict(self, state_dict: OrderedDict) -> None:\n    return super().load_state_dict(state_dict)",
                    "description": "This function is used to load the state dictionary of a PyTorch model from an existing checkpoint or saved model. It allows for the transfer of learned parameters and other model state between different runs or environments, enabling faster development and deployment."
                },
                {
                    "function_name": "update_policy_weights_",
                    "args": [
                        {
                            "arg": "policy_weights",
                            "description": "(Optional[TensorDictBase]) - The policy weights to be updated. (default: None)"
                        },
                        {
                            "arg": "_",
                            "description": " (...) -> None"
                        }
                    ],
                    "signature": "update_policy_weights_(self, policy_weights: Optional[TensorDictBase]=None) -> None",
                    "function_code": "def update_policy_weights_(self, policy_weights: Optional[TensorDictBase]=None) -> None:\n    super().update_policy_weights_(policy_weights)",
                    "description": "This function is a method that updates the weights of a policy in a reinforcement learning model by calling the parent class's `update_policy_weights_` method."
                },
                {
                    "function_name": "frames_per_batch_worker",
                    "args": [
                        {
                            "arg": "None"
                        }
                    ],
                    "signature": "frames_per_batch_worker(self)",
                    "function_code": "@property\ndef frames_per_batch_worker(self):\n    return self.requested_frames_per_batch",
                    "description": "This function is a read-only property that returns the requested frames per batch, indicating its significance as a configuration setting for video processing and batching in PyTorch."
                },
                {
                    "function_name": "iterator",
                    "args": [
                        {
                            "arg": "None"
                        }
                    ],
                    "signature": "iterator(self) -> Iterator[TensorDictBase]",
                    "function_code": "def iterator(self) -> Iterator[TensorDictBase]:\n    if self.update_at_each_batch:\n        self.update_policy_weights_()\n    for i in range(self.num_workers):\n        if self.init_random_frames is not None and self.init_random_frames > 0:\n            self.pipes[i].send((None, 'continue_random'))\n        else:\n            self.pipes[i].send((None, 'continue'))\n    self.running = True\n    workers_frames = [0 for _ in range(self.num_workers)]\n    while self._frames < self.total_frames:\n        self._iter += 1\n        while True:\n            try:\n                idx, j, out = self._get_from_queue(timeout=10.0)\n                break\n            except TimeoutError:\n                _check_for_faulty_process(self.procs)\n        if self.replay_buffer is None:\n            worker_frames = out.numel()\n            if self.split_trajs:\n                out = split_trajectories(out, prefix='collector')\n        else:\n            worker_frames = self.frames_per_batch_worker\n        self._frames += worker_frames\n        workers_frames[idx] = workers_frames[idx] + worker_frames\n        if self.postprocs:\n            out = self.postprocs[out.device](out)\n        if self.init_random_frames is not None and self._frames < self.init_random_frames:\n            msg = 'continue_random'\n        else:\n            msg = 'continue'\n        self.pipes[idx].send((idx, msg))\n        if out is not None and self._exclude_private_keys:\n            excluded_keys = [key for key in out.keys() if key.startswith('_')]\n            out = out.exclude(*excluded_keys)\n        yield out\n    self.running = False",
                    "description": "This function is a PyTorch iterator that manages the data processing pipeline, handling tasks such as updating policy weights, sending messages to workers, and yielding processed output tensors."
                },
                {
                    "function_name": "reset",
                    "args": [
                        {
                            "arg": "reset_idx",
                            "description": "(Optional[Sequence[bool]]) - The index of the model to be reset."
                        },
                        {
                            "arg": "None",
                            "description": " () - No description available."
                        }
                    ],
                    "signature": "reset(self, reset_idx: Optional[Sequence[bool]]=None) -> None",
                    "function_code": "def reset(self, reset_idx: Optional[Sequence[bool]]=None) -> None:\n    super().reset(reset_idx)\n    if self.queue_out.full():\n        time.sleep(_TIMEOUT)\n    if self.queue_out.full():\n        raise Exception('self.queue_out is full')\n    if self.running:\n        for idx in range(self.num_workers):\n            if self.init_random_frames is not None and self._frames < self.init_random_frames:\n                self.pipes[idx].send((idx, 'continue_random'))\n            else:\n                self.pipes[idx].send((idx, 'continue'))",
                    "description": "This function is used to reset the state of a worker in a multi-worker queue system, ensuring that workers continue processing tasks after a certain period or when new frames are available."
                }
            ]
        },
        {
            "class_name": "aSyncDataCollector",
            "bases": [
                "MultiaSyncDataCollector"
            ],
            "description": "This class is an asynchronous data collector, designed to efficiently collect and store data from various sources in a PyTorch environment, allowing for seamless integration with other components.",
            "overview": "",
            "functions": [
                {
                    "function_name": "__init__",
                    "args": [
                        {
                            "arg": "create_env_fn",
                            "description": "(Callable[[], EnvBase]) - The function to create an environment."
                        },
                        {
                            "arg": "policy",
                            "description": "(Optional[Union[TensorDictModule, Callable[[TensorDictBase], TensorDictBase]]]) - The policy used for exploration."
                        },
                        {
                            "arg": "frames_per_batch",
                            "description": "(int) - The number of frames per batch."
                        },
                        {
                            "arg": "total_frames",
                            "description": "(Optional[int]) - The total number of frames. (default: None)"
                        },
                        {
                            "arg": "device",
                            "description": "(DEVICE_TYPING | Sequence[DEVICE_TYPING] | None) - The device to use for the environment."
                        },
                        {
                            "arg": "storing_device",
                            "description": "(DEVICE_TYPING | Sequence[DEVICE_TYPING] | None) - The device to store the data on."
                        },
                        {
                            "arg": "env_device",
                            "description": "(DEVICE_TYPING | Sequence[DEVICE_TYPING] | None) - The device for the environment."
                        },
                        {
                            "arg": "policy_device",
                            "description": "(DEVICE_TYPING | Sequence[DEVICE_TYPING] | None) - The device for the policy."
                        },
                        {
                            "arg": "create_env_kwargs",
                            "description": "(Optional[Sequence[dict]]) - Keyword arguments to pass to create_env_fn."
                        },
                        {
                            "arg": "max_frames_per_traj",
                            "description": "(int | None) - The maximum number of frames per trajectory."
                        },
                        {
                            "arg": "init_random_frames",
                            "description": "(int | None) - The initial random frames."
                        },
                        {
                            "arg": "reset_at_each_iter",
                            "description": "(bool) - Whether to reset at each iteration."
                        },
                        {
                            "arg": "postproc",
                            "description": "(Optional[Callable[[TensorDictBase], TensorDictBase]]) - A post-processing function for the data."
                        },
                        {
                            "arg": "split_trajs",
                            "description": "(Optional[bool]) - Whether to split trajectories."
                        },
                        {
                            "arg": "exploration_type",
                            "description": "(ExplorationType) - The type of exploration used."
                        },
                        {
                            "arg": "reset_when_done",
                            "description": "(bool) - Whether to reset when done."
                        },
                        {
                            "arg": "update_at_each_batch",
                            "description": "(bool) - Whether to update at each batch."
                        },
                        {
                            "arg": "preemptive_threshold",
                            "description": "(float) - The preemptive threshold."
                        },
                        {
                            "arg": "num_threads",
                            "description": "(int) - The number of threads used."
                        },
                        {
                            "arg": "num_sub_threads",
                            "description": "(int) - The number of sub-threads used. (default: 1)"
                        },
                        {
                            "arg": "set_truncated",
                            "description": "(bool) - Whether to set truncated."
                        }
                    ],
                    "signature": "__init__(self, create_env_fn: Callable[[], EnvBase], policy: Optional[Union[TensorDictModule, Callable[[TensorDictBase], TensorDictBase]]], *, frames_per_batch: int, total_frames: Optional[int]=-1, device: DEVICE_TYPING | Sequence[DEVICE_TYPING] | None=None, storing_device: DEVICE_TYPING | Sequence[DEVICE_TYPING] | None=None, env_device: DEVICE_TYPING | Sequence[DEVICE_TYPING] | None=None, policy_device: DEVICE_TYPING | Sequence[DEVICE_TYPING] | None=None, create_env_kwargs: Optional[Sequence[dict]]=None, max_frames_per_traj: int | None=None, init_random_frames: int | None=None, reset_at_each_iter: bool=False, postproc: Optional[Callable[[TensorDictBase], TensorDictBase]]=None, split_trajs: Optional[bool]=None, exploration_type: ExplorationType=DEFAULT_EXPLORATION_TYPE, reset_when_done: bool=True, update_at_each_batch: bool=False, preemptive_threshold: float=None, num_threads: int=None, num_sub_threads: int=1, set_truncated: bool=False, **kwargs)",
                    "function_code": "def __init__(self, create_env_fn: Callable[[], EnvBase], policy: Optional[Union[TensorDictModule, Callable[[TensorDictBase], TensorDictBase]]], *, frames_per_batch: int, total_frames: Optional[int]=-1, device: DEVICE_TYPING | Sequence[DEVICE_TYPING] | None=None, storing_device: DEVICE_TYPING | Sequence[DEVICE_TYPING] | None=None, env_device: DEVICE_TYPING | Sequence[DEVICE_TYPING] | None=None, policy_device: DEVICE_TYPING | Sequence[DEVICE_TYPING] | None=None, create_env_kwargs: Optional[Sequence[dict]]=None, max_frames_per_traj: int | None=None, init_random_frames: int | None=None, reset_at_each_iter: bool=False, postproc: Optional[Callable[[TensorDictBase], TensorDictBase]]=None, split_trajs: Optional[bool]=None, exploration_type: ExplorationType=DEFAULT_EXPLORATION_TYPE, reset_when_done: bool=True, update_at_each_batch: bool=False, preemptive_threshold: float=None, num_threads: int=None, num_sub_threads: int=1, set_truncated: bool=False, **kwargs):\n    super().__init__(create_env_fn=[create_env_fn], policy=policy, total_frames=total_frames, create_env_kwargs=[create_env_kwargs], max_frames_per_traj=max_frames_per_traj, frames_per_batch=frames_per_batch, reset_at_each_iter=reset_at_each_iter, init_random_frames=init_random_frames, postproc=postproc, split_trajs=split_trajs, device=device, policy_device=policy_device, env_device=env_device, storing_device=storing_device, exploration_type=exploration_type, reset_when_done=reset_when_done, update_at_each_batch=update_at_each_batch, preemptive_threshold=preemptive_threshold, num_threads=num_threads, num_sub_threads=num_sub_threads, set_truncated=set_truncated)",
                    "description": "This function is the constructor of a class in PyTorch, used to initialize an object with its attributes and parameters. It sets up the environment for training or testing a reinforcement learning algorithm."
                },
                {
                    "function_name": "next",
                    "args": [
                        {
                            "arg": "None"
                        }
                    ],
                    "signature": "next(self)",
                    "function_code": "def next(self):\n    return super().next()",
                    "description": "This function is a placeholder that delegates to the parent class's `next` method, effectively bypassing any custom implementation. It should be used when you want to maintain the default behavior of the parent class while still providing a consistent interface for subclasses."
                },
                {
                    "function_name": "shutdown",
                    "args": [
                        {
                            "arg": "None"
                        }
                    ],
                    "signature": "shutdown(self)",
                    "function_code": "def shutdown(self):\n    return super().shutdown()",
                    "description": "This function is a placeholder for overriding the `shutdown` method in PyTorch models, allowing developers to perform custom cleanup actions before model destruction."
                },
                {
                    "function_name": "set_seed",
                    "args": [
                        {
                            "arg": "seed",
                            "description": " (int) - The random seed to be used. (default: None)"
                        },
                        {
                            "arg": "static_seed",
                            "description": " (bool) - Whether the static seed is used. (default: False)"
                        }
                    ],
                    "signature": "set_seed(self, seed: int, static_seed: bool=False) -> int",
                    "function_code": "def set_seed(self, seed: int, static_seed: bool=False) -> int:\n    return super().set_seed(seed, static_seed)",
                    "description": "This function is used to set a random seed for reproducibility in PyTorch models. It ensures that the same sequence of random numbers is generated every time the model is run with the same seed value, making it easier to debug and test models."
                },
                {
                    "function_name": "state_dict",
                    "args": [
                        {
                            "arg": "None"
                        }
                    ],
                    "signature": "state_dict(self) -> OrderedDict",
                    "function_code": "def state_dict(self) -> OrderedDict:\n    return super().state_dict()",
                    "description": "This function is used to retrieve the model's state dictionary, which contains the learned parameters and their values, allowing for model loading and saving."
                },
                {
                    "function_name": "load_state_dict",
                    "args": [
                        {
                            "arg": "state_dict",
                            "description": "(OrderedDict) - The model state dictionary to be loaded into the current state."
                        }
                    ],
                    "signature": "load_state_dict(self, state_dict: OrderedDict) -> None",
                    "function_code": "def load_state_dict(self, state_dict: OrderedDict) -> None:\n    return super().load_state_dict(state_dict)",
                    "description": "This function is used to load the state dictionary of a PyTorch model from an existing checkpoint or saved model. It allows for the transfer of learned parameters and other model state between different runs or environments, enabling faster development and deployment."
                }
            ]
        }
    ],
    "utils.py": [
        {
            "function_name": "split_trajectories",
            "args": [
                {
                    "arg": "rollout_tensordict",
                    "description": "(TensorDictBase) - The rollout tensor dictionary to be split into trajectories."
                },
                {
                    "arg": "prefix",
                    "description": "(str | None) - The prefix for the trajectory keys. (default: None)"
                },
                {
                    "arg": "trajectory_key",
                    "description": "(NestedKey | None) - The key for the trajectory data in the rollout tensor dictionary."
                },
                {
                    "arg": "done_key",
                    "description": "(NestedKey | None) - The key for the done signal in the rollout tensor dictionary."
                },
                {
                    "arg": "as_nested",
                    "description": "(bool) - Whether to return the trajectory data as a nested dictionary. (default: False)"
                }
            ],
            "signature": "split_trajectories(rollout_tensordict: TensorDictBase, *, prefix=None, trajectory_key: NestedKey | None=None, done_key: NestedKey | None=None, as_nested: bool=False) -> TensorDictBase",
            "function_code": "@set_lazy_legacy(False)\ndef split_trajectories(rollout_tensordict: TensorDictBase, *, prefix=None, trajectory_key: NestedKey | None=None, done_key: NestedKey | None=None, as_nested: bool=False) -> TensorDictBase:\n    \"\"\"A util function for trajectory separation.\n\n    Takes a tensordict with a key traj_ids that indicates the id of each trajectory.\n\n    From there, builds a B x T x ... zero-padded tensordict with B batches on max duration T\n\n    Args:\n        rollout_tensordict (TensorDictBase): a rollout with adjacent trajectories\n            along the last dimension.\n\n    Keyword Args:\n        prefix (NestedKey, optional): the prefix used to read and write meta-data,\n            such as ``\"traj_ids\"`` (the optional integer id of each trajectory)\n            and the ``\"mask\"`` entry indicating which data are valid and which\n            aren't. Defaults to ``\"collector\"`` if the input has a ``\"collector\"``\n            entry, ``()`` (no prefix) otherwise.\n            ``prefix`` is kept as a legacy feature and will be deprecated eventually.\n            Prefer ``trajectory_key`` or ``done_key`` whenever possible.\n        trajectory_key (NestedKey, optional): the key pointing to the trajectory\n            ids. Supersedes ``done_key`` and ``prefix``. If not provided, defaults\n            to ``(prefix, \"traj_ids\")``.\n        done_key (NestedKey, optional): the key pointing to the ``\"done\"\"`` signal,\n            if the trajectory could not be directly recovered. Defaults to ``\"done\"``.\n        as_nested (bool or torch.layout, optional): whether to return the results as nested\n            tensors. Defaults to ``False``. If a ``torch.layout`` is provided, it will be used\n            to construct the nested tensor, otherwise the default layout will be used.\n\n            .. note:: Using ``split_trajectories(tensordict, as_nested=True).to_padded_tensor(mask=mask_key)``\n                should result in the exact same result as ``as_nested=False``. Since this is an experimental\n                feature and relies on nested_tensors, which API may change in the future, we made this\n                an optional feature. The runtime should be faster with ``as_nested=True``.\n\n            .. note:: Providing a layout lets the user control whether the nested tensor is to be used\n                with ``torch.strided`` or ``torch.jagged`` layout. While the former has slightly more\n                capabilities at the time of writing, the second will be the main focus of the PyTorch team\n                in the future due to its better compatibility with :func:`~torch.compile`.\n\n    Returns:\n        A new tensordict with a leading dimension corresponding to the trajectory.\n        A ``\"mask\"`` boolean entry sharing the ``trajectory_key`` prefix\n        and the tensordict shape is also added. It indicated the valid elements of the tensordict,\n        as well as a ``\"traj_ids\"`` entry if ``trajectory_key`` could not be found.\n\n    Examples:\n        >>> from tensordict import TensorDict\n        >>> import torch\n        >>> from torchrl.collectors.utils import split_trajectories\n        >>> obs = torch.cat([torch.arange(10), torch.arange(5)])\n        >>> obs_ = torch.cat([torch.arange(1, 11), torch.arange(1, 6)])\n        >>> done = torch.zeros(15, dtype=torch.bool)\n        >>> done[9] = True\n        >>> trajectory_id = torch.cat([torch.zeros(10, dtype=torch.int32),\n        ...     torch.ones(5, dtype=torch.int32)])\n        >>> data = TensorDict({\"obs\": obs, (\"next\", \"obs\"): obs_, (\"next\", \"done\"): done, \"trajectory\": trajectory_id}, batch_size=[15])\n        >>> data_split = split_trajectories(data, done_key=\"done\")\n        >>> print(data_split)\n        TensorDict(\n            fields={\n                mask: Tensor(shape=torch.Size([2, 10]), device=cpu, dtype=torch.bool, is_shared=False),\n                next: TensorDict(\n                    fields={\n                        done: Tensor(shape=torch.Size([2, 10]), device=cpu, dtype=torch.bool, is_shared=False),\n                        obs: Tensor(shape=torch.Size([2, 10]), device=cpu, dtype=torch.int64, is_shared=False)},\n                    batch_size=torch.Size([2, 10]),\n                    device=None,\n                    is_shared=False),\n                obs: Tensor(shape=torch.Size([2, 10]), device=cpu, dtype=torch.int64, is_shared=False),\n                traj_ids: Tensor(shape=torch.Size([2, 10]), device=cpu, dtype=torch.int64, is_shared=False),\n                trajectory: Tensor(shape=torch.Size([2, 10]), device=cpu, dtype=torch.int32, is_shared=False)},\n            batch_size=torch.Size([2, 10]),\n            device=None,\n            is_shared=False)\n        >>> # check that split_trajectories got the trajectories right with the done signal\n        >>> assert (data_split[\"traj_ids\"] == data_split[\"trajectory\"]).all()\n        >>> print(data_split[\"mask\"])\n        tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True],\n                [ True,  True,  True,  True,  True, False, False, False, False, False]])\n        >>> data_split = split_trajectories(data, trajectory_key=\"trajectory\")\n        >>> print(data_split)\n        TensorDict(\n            fields={\n                mask: Tensor(shape=torch.Size([2, 10]), device=cpu, dtype=torch.bool, is_shared=False),\n                next: TensorDict(\n                    fields={\n                        done: Tensor(shape=torch.Size([2, 10]), device=cpu, dtype=torch.bool, is_shared=False),\n                        obs: Tensor(shape=torch.Size([2, 10]), device=cpu, dtype=torch.int64, is_shared=False)},\n                    batch_size=torch.Size([2, 10]),\n                    device=None,\n                    is_shared=False),\n                obs: Tensor(shape=torch.Size([2, 10]), device=cpu, dtype=torch.int64, is_shared=False),\n                trajectory: Tensor(shape=torch.Size([2, 10]), device=cpu, dtype=torch.int32, is_shared=False)},\n            batch_size=torch.Size([2, 10]),\n            device=None,\n            is_shared=False)\n\n    \"\"\"\n    mask_key = None\n    if trajectory_key is not None:\n        from torchrl.envs.utils import _replace_last\n        traj_ids_key = trajectory_key\n        mask_key = _replace_last(trajectory_key, 'mask')\n    else:\n        if prefix is None and 'collector' in rollout_tensordict.keys():\n            prefix = 'collector'\n        if prefix is None:\n            traj_ids_key = 'traj_ids'\n            mask_key = 'mask'\n        else:\n            traj_ids_key = (prefix, 'traj_ids')\n            mask_key = (prefix, 'mask')\n    rollout_tensordict = rollout_tensordict.copy()\n    traj_ids = rollout_tensordict.get(traj_ids_key, None)\n    if traj_ids is None:\n        if done_key is None:\n            done_key = 'done'\n        done_key = ('next', done_key)\n        done = rollout_tensordict.get(done_key)\n        idx = (slice(None),) * (rollout_tensordict.ndim - 1) + (slice(None, -1),)\n        done_sel = done[idx]\n        pads = [1, 0]\n        pads = [0, 0] * (done.ndim - rollout_tensordict.ndim) + pads\n        done_sel = torch.nn.functional.pad(done_sel, pads)\n        if done_sel.shape != done.shape:\n            raise RuntimeError(f'done and done_sel have different shape {done.shape} - {done_sel.shape} ')\n        traj_ids = done_sel.cumsum(rollout_tensordict.ndim - 1)\n        traj_ids = traj_ids.squeeze(-1)\n        if rollout_tensordict.ndim > 1:\n            for i in range(1, rollout_tensordict.shape[0]):\n                traj_ids[i] += traj_ids[i - 1].max() + 1\n        rollout_tensordict.set(traj_ids_key, traj_ids)\n    splits = traj_ids.reshape(-1)\n    splits = [(splits == i).sum().item() for i in splits.unique_consecutive()]\n    if len(set(splits)) == 1 and splits[0] == traj_ids.shape[-1]:\n        rollout_tensordict.set(mask_key, torch.ones(rollout_tensordict.shape, device=rollout_tensordict.device, dtype=torch.bool))\n        if rollout_tensordict.ndimension() == 1:\n            rollout_tensordict = rollout_tensordict.unsqueeze(0)\n        return rollout_tensordict\n    out_splits = rollout_tensordict.reshape(-1)\n    if as_nested:\n        if hasattr(torch, '_nested_compute_contiguous_strides_offsets'):\n\n            def nest(x, splits=splits):\n                shape = torch.tensor([[int(split), *x.shape[1:]] for split in splits])\n                return torch._nested_view_from_buffer(x.reshape(-1), shape, *torch._nested_compute_contiguous_strides_offsets(shape))\n            return out_splits._fast_apply(nest, batch_size=[len(splits), -1])\n        else:\n            out_splits = out_splits.split(splits, 0)\n            layout = as_nested if as_nested is not bool else None\n            if torch.__version__ < '2.4':\n                if layout not in (True,):\n                    raise RuntimeError(f'layout={layout} is only available for torch>=v2.4')\n\n                def nest(*x):\n                    return torch.nested.nested_tensor(list(x))\n            else:\n\n                def nest(*x):\n                    return torch.nested.nested_tensor(list(x), layout=layout)\n            return out_splits[0]._fast_apply(nest, *out_splits[1:], batch_size=[len(out_splits), *out_splits[0].batch_size[:-1], -1])\n    out_splits = out_splits.split(splits, 0)\n    for out_split in out_splits:\n        out_split.set(mask_key, torch.ones(out_split.shape, dtype=torch.bool, device=out_split.device))\n    if len(out_splits) > 1:\n        MAX = max(*[out_split.shape[0] for out_split in out_splits])\n    else:\n        MAX = out_splits[0].shape[0]\n    td = torch.stack([pad(out_split, [0, MAX - out_split.shape[0]]) for out_split in out_splits], 0)\n    return td",
            "description": "This is a PyTorch implementation of the `split` function from the `torch.nn.utils.rnn` module. The purpose of this function is to split a tensor into multiple tensors, each containing a subset of the original data.\n\nHere's a breakdown of what the code does:\n\n1. It first checks if a `trajectory_key` is provided. If it is, it uses that key to determine the shape of the output tensors.\n2. If no `trajectory_key` is provided, it falls back to using the `'traj_ids'` key and sets the corresponding mask tensor to all ones.\n3. It then splits the input tensor into multiple tensors, each containing a subset of the original data. The number of subsets depends on the length of the input tensor.\n4. For each subset, it pads the tensor with zeros to ensure that all subsets have the same shape.\n5. Finally, it returns a stack of the padded tensors.\n\nThe code uses several PyTorch-specific features, such as:\n\n* `torch._nested_view_from_buffer`: This function is used to create a nested view of a tensor, which allows for efficient computation on tensors with complex structures.\n* `torch.nested.nested_tensor: This function is used to create a nested tensor from a list of tensors.\n* `torch.ones`: This function is used to create a tensor filled with ones.\n\nThe code also uses some PyTorch-specific functions and variables, such as:\n\n* `out_splits`\n* `as_nested`\n* `layout`\n\nOverall, this code appears to be part of a larger library or framework for working with tensors in PyTorch."
        }
    ]
}
